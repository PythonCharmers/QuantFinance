{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Quantitative Finance\n",
    "\n",
    "Copyright (c) 2019 Python Charmers Pty Ltd, Australia, <https://pythoncharmers.com>. All rights reserved.\n",
    "\n",
    "<img src=\"img/python_charmers_logo.png\" width=\"300\" alt=\"Python Charmers Logo\">\n",
    "\n",
    "Published under the Creative Commons Attribution-NonCommercial 4.0 International (CC BY-NC 4.0) license. See `LICENSE.md` for details.\n",
    "\n",
    "Sponsored by Tibra Global Services, <https://tibra.com>\n",
    "\n",
    "<img src=\"img/tibra_logo.png\" width=\"300\" alt=\"Tibra Logo\">\n",
    "\n",
    "\n",
    "## Module 1.3: Multicolinearity\n",
    "\n",
    "### 1.3.3 Colinearity\n",
    "\n",
    "Colinearity is the state of two independent variables being highly correlated. In this case, one of the assumptions behind the OLS estimator is broken, specifically that the variables can not have a linear relationship. Technically, colinearity refers to the case when two variables are *perfectly* correlated, but in practice it is often used to mean \"very highly correlated and causing a problem\". \n",
    "\n",
    "What kinds of problems does colinearity create? If two variables are perfectly correlated, then the OLS estimator equation cannot be computed at all ($X'X$ has no inverse).  In practice, the problem is that the linear model cannot distinguish between the two variables. Sometimes this still results in a useful model, and sometimes it does not. It may cause some variables to appear to be insignificant in the relationship when they really are - in other words, their \"weight\" is transferred to another, correlated value.\n",
    "\n",
    "In cases of colinearity causing a problem with your model, check for a few obvious things first:\n",
    "\n",
    "1. That you haven't added a variable twice. This can happen through a coding problem (the very same variable appears twice) or through a data problem (you join two tables that have the same data, with different names). In this case, remove a duplicate.\n",
    "2. Check for redundant variables. A redundant variable adds no explanatory power by itself, and instead ends up simply confusing the model. An example would be having a parameter \"total family income\" and another two indicating \"income of first parent\" and \"income of second parent\". The first variable is simply the sum of the next two (at least, in most cases).\n",
    "3. Use a different model, such as a Ridge Regression, which can better handle this type of issue\n",
    "4. Combine the features into a set of linearly separable features. We will see the PCA algorithm in the next set of modules, an algorithm that can do this.\n",
    "\n",
    "Note that due to these reasons, you shouldn't remove variables that appear insignificant in a model affected by colinearity - they may be the ones with colinearity and actually have a high predictive power.\n",
    "\n",
    "To detect colinearity, compute the pairwise correlation between each set of variables. Many correlation functions do this for you, for instance `pd.corr`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run setup.ipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load a dataset from the scikit learn repository\n",
    "# scikit-learn is a machine learning library, and has a few sample datasets \n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\env\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "boston_data = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearn_to_df(sklearn_dataset):\n",
    "    # A helper function to convert the scikit-learn dataset to a pandas DataFrame\n",
    "    # From: https://stackoverflow.com/questions/38105539/how-to-convert-a-scikit-learn-dataset-to-a-pandas-dataset/46379878#46379878\n",
    "    df = pd.DataFrame(sklearn_dataset.data, columns=sklearn_dataset.feature_names)\n",
    "    df['target'] = pd.Series(sklearn_dataset.target)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = sklearn_to_df(boston_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  target  \n",
       "0     15.3  396.90   4.98    24.0  \n",
       "1     17.8  396.90   9.14    21.6  \n",
       "2     17.8  392.83   4.03    34.7  \n",
       "3     18.7  394.63   2.94    33.4  \n",
       "4     18.7  396.90   5.33    36.2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = boston.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colour_large_values_red(val):\n",
    "    \"\"\"Colour cells based on their value - a useful pattern for reports!\"\"\"\n",
    "    color = 'red' if abs(val) > 0.9 else 'lightgrey'\n",
    "    return 'background-color: %s' % color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_bb875_row0_col0, #T_bb875_row1_col1, #T_bb875_row2_col2, #T_bb875_row3_col3, #T_bb875_row4_col4, #T_bb875_row5_col5, #T_bb875_row6_col6, #T_bb875_row7_col7, #T_bb875_row8_col8, #T_bb875_row8_col9, #T_bb875_row9_col8, #T_bb875_row9_col9, #T_bb875_row10_col10, #T_bb875_row11_col11, #T_bb875_row12_col12, #T_bb875_row13_col13 {\n",
       "  background-color: red;\n",
       "}\n",
       "#T_bb875_row0_col1, #T_bb875_row0_col2, #T_bb875_row0_col3, #T_bb875_row0_col4, #T_bb875_row0_col5, #T_bb875_row0_col6, #T_bb875_row0_col7, #T_bb875_row0_col8, #T_bb875_row0_col9, #T_bb875_row0_col10, #T_bb875_row0_col11, #T_bb875_row0_col12, #T_bb875_row0_col13, #T_bb875_row1_col0, #T_bb875_row1_col2, #T_bb875_row1_col3, #T_bb875_row1_col4, #T_bb875_row1_col5, #T_bb875_row1_col6, #T_bb875_row1_col7, #T_bb875_row1_col8, #T_bb875_row1_col9, #T_bb875_row1_col10, #T_bb875_row1_col11, #T_bb875_row1_col12, #T_bb875_row1_col13, #T_bb875_row2_col0, #T_bb875_row2_col1, #T_bb875_row2_col3, #T_bb875_row2_col4, #T_bb875_row2_col5, #T_bb875_row2_col6, #T_bb875_row2_col7, #T_bb875_row2_col8, #T_bb875_row2_col9, #T_bb875_row2_col10, #T_bb875_row2_col11, #T_bb875_row2_col12, #T_bb875_row2_col13, #T_bb875_row3_col0, #T_bb875_row3_col1, #T_bb875_row3_col2, #T_bb875_row3_col4, #T_bb875_row3_col5, #T_bb875_row3_col6, #T_bb875_row3_col7, #T_bb875_row3_col8, #T_bb875_row3_col9, #T_bb875_row3_col10, #T_bb875_row3_col11, #T_bb875_row3_col12, #T_bb875_row3_col13, #T_bb875_row4_col0, #T_bb875_row4_col1, #T_bb875_row4_col2, #T_bb875_row4_col3, #T_bb875_row4_col5, #T_bb875_row4_col6, #T_bb875_row4_col7, #T_bb875_row4_col8, #T_bb875_row4_col9, #T_bb875_row4_col10, #T_bb875_row4_col11, #T_bb875_row4_col12, #T_bb875_row4_col13, #T_bb875_row5_col0, #T_bb875_row5_col1, #T_bb875_row5_col2, #T_bb875_row5_col3, #T_bb875_row5_col4, #T_bb875_row5_col6, #T_bb875_row5_col7, #T_bb875_row5_col8, #T_bb875_row5_col9, #T_bb875_row5_col10, #T_bb875_row5_col11, #T_bb875_row5_col12, #T_bb875_row5_col13, #T_bb875_row6_col0, #T_bb875_row6_col1, #T_bb875_row6_col2, #T_bb875_row6_col3, #T_bb875_row6_col4, #T_bb875_row6_col5, #T_bb875_row6_col7, #T_bb875_row6_col8, #T_bb875_row6_col9, #T_bb875_row6_col10, #T_bb875_row6_col11, #T_bb875_row6_col12, #T_bb875_row6_col13, #T_bb875_row7_col0, #T_bb875_row7_col1, #T_bb875_row7_col2, #T_bb875_row7_col3, #T_bb875_row7_col4, #T_bb875_row7_col5, #T_bb875_row7_col6, #T_bb875_row7_col8, #T_bb875_row7_col9, #T_bb875_row7_col10, #T_bb875_row7_col11, #T_bb875_row7_col12, #T_bb875_row7_col13, #T_bb875_row8_col0, #T_bb875_row8_col1, #T_bb875_row8_col2, #T_bb875_row8_col3, #T_bb875_row8_col4, #T_bb875_row8_col5, #T_bb875_row8_col6, #T_bb875_row8_col7, #T_bb875_row8_col10, #T_bb875_row8_col11, #T_bb875_row8_col12, #T_bb875_row8_col13, #T_bb875_row9_col0, #T_bb875_row9_col1, #T_bb875_row9_col2, #T_bb875_row9_col3, #T_bb875_row9_col4, #T_bb875_row9_col5, #T_bb875_row9_col6, #T_bb875_row9_col7, #T_bb875_row9_col10, #T_bb875_row9_col11, #T_bb875_row9_col12, #T_bb875_row9_col13, #T_bb875_row10_col0, #T_bb875_row10_col1, #T_bb875_row10_col2, #T_bb875_row10_col3, #T_bb875_row10_col4, #T_bb875_row10_col5, #T_bb875_row10_col6, #T_bb875_row10_col7, #T_bb875_row10_col8, #T_bb875_row10_col9, #T_bb875_row10_col11, #T_bb875_row10_col12, #T_bb875_row10_col13, #T_bb875_row11_col0, #T_bb875_row11_col1, #T_bb875_row11_col2, #T_bb875_row11_col3, #T_bb875_row11_col4, #T_bb875_row11_col5, #T_bb875_row11_col6, #T_bb875_row11_col7, #T_bb875_row11_col8, #T_bb875_row11_col9, #T_bb875_row11_col10, #T_bb875_row11_col12, #T_bb875_row11_col13, #T_bb875_row12_col0, #T_bb875_row12_col1, #T_bb875_row12_col2, #T_bb875_row12_col3, #T_bb875_row12_col4, #T_bb875_row12_col5, #T_bb875_row12_col6, #T_bb875_row12_col7, #T_bb875_row12_col8, #T_bb875_row12_col9, #T_bb875_row12_col10, #T_bb875_row12_col11, #T_bb875_row12_col13, #T_bb875_row13_col0, #T_bb875_row13_col1, #T_bb875_row13_col2, #T_bb875_row13_col3, #T_bb875_row13_col4, #T_bb875_row13_col5, #T_bb875_row13_col6, #T_bb875_row13_col7, #T_bb875_row13_col8, #T_bb875_row13_col9, #T_bb875_row13_col10, #T_bb875_row13_col11, #T_bb875_row13_col12 {\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_bb875\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_bb875_level0_col0\" class=\"col_heading level0 col0\" >CRIM</th>\n",
       "      <th id=\"T_bb875_level0_col1\" class=\"col_heading level0 col1\" >ZN</th>\n",
       "      <th id=\"T_bb875_level0_col2\" class=\"col_heading level0 col2\" >INDUS</th>\n",
       "      <th id=\"T_bb875_level0_col3\" class=\"col_heading level0 col3\" >CHAS</th>\n",
       "      <th id=\"T_bb875_level0_col4\" class=\"col_heading level0 col4\" >NOX</th>\n",
       "      <th id=\"T_bb875_level0_col5\" class=\"col_heading level0 col5\" >RM</th>\n",
       "      <th id=\"T_bb875_level0_col6\" class=\"col_heading level0 col6\" >AGE</th>\n",
       "      <th id=\"T_bb875_level0_col7\" class=\"col_heading level0 col7\" >DIS</th>\n",
       "      <th id=\"T_bb875_level0_col8\" class=\"col_heading level0 col8\" >RAD</th>\n",
       "      <th id=\"T_bb875_level0_col9\" class=\"col_heading level0 col9\" >TAX</th>\n",
       "      <th id=\"T_bb875_level0_col10\" class=\"col_heading level0 col10\" >PTRATIO</th>\n",
       "      <th id=\"T_bb875_level0_col11\" class=\"col_heading level0 col11\" >B</th>\n",
       "      <th id=\"T_bb875_level0_col12\" class=\"col_heading level0 col12\" >LSTAT</th>\n",
       "      <th id=\"T_bb875_level0_col13\" class=\"col_heading level0 col13\" >target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bb875_level0_row0\" class=\"row_heading level0 row0\" >CRIM</th>\n",
       "      <td id=\"T_bb875_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "      <td id=\"T_bb875_row0_col1\" class=\"data row0 col1\" >-0.200469</td>\n",
       "      <td id=\"T_bb875_row0_col2\" class=\"data row0 col2\" >0.406583</td>\n",
       "      <td id=\"T_bb875_row0_col3\" class=\"data row0 col3\" >-0.055892</td>\n",
       "      <td id=\"T_bb875_row0_col4\" class=\"data row0 col4\" >0.420972</td>\n",
       "      <td id=\"T_bb875_row0_col5\" class=\"data row0 col5\" >-0.219247</td>\n",
       "      <td id=\"T_bb875_row0_col6\" class=\"data row0 col6\" >0.352734</td>\n",
       "      <td id=\"T_bb875_row0_col7\" class=\"data row0 col7\" >-0.379670</td>\n",
       "      <td id=\"T_bb875_row0_col8\" class=\"data row0 col8\" >0.625505</td>\n",
       "      <td id=\"T_bb875_row0_col9\" class=\"data row0 col9\" >0.582764</td>\n",
       "      <td id=\"T_bb875_row0_col10\" class=\"data row0 col10\" >0.289946</td>\n",
       "      <td id=\"T_bb875_row0_col11\" class=\"data row0 col11\" >-0.385064</td>\n",
       "      <td id=\"T_bb875_row0_col12\" class=\"data row0 col12\" >0.455621</td>\n",
       "      <td id=\"T_bb875_row0_col13\" class=\"data row0 col13\" >-0.388305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb875_level0_row1\" class=\"row_heading level0 row1\" >ZN</th>\n",
       "      <td id=\"T_bb875_row1_col0\" class=\"data row1 col0\" >-0.200469</td>\n",
       "      <td id=\"T_bb875_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "      <td id=\"T_bb875_row1_col2\" class=\"data row1 col2\" >-0.533828</td>\n",
       "      <td id=\"T_bb875_row1_col3\" class=\"data row1 col3\" >-0.042697</td>\n",
       "      <td id=\"T_bb875_row1_col4\" class=\"data row1 col4\" >-0.516604</td>\n",
       "      <td id=\"T_bb875_row1_col5\" class=\"data row1 col5\" >0.311991</td>\n",
       "      <td id=\"T_bb875_row1_col6\" class=\"data row1 col6\" >-0.569537</td>\n",
       "      <td id=\"T_bb875_row1_col7\" class=\"data row1 col7\" >0.664408</td>\n",
       "      <td id=\"T_bb875_row1_col8\" class=\"data row1 col8\" >-0.311948</td>\n",
       "      <td id=\"T_bb875_row1_col9\" class=\"data row1 col9\" >-0.314563</td>\n",
       "      <td id=\"T_bb875_row1_col10\" class=\"data row1 col10\" >-0.391679</td>\n",
       "      <td id=\"T_bb875_row1_col11\" class=\"data row1 col11\" >0.175520</td>\n",
       "      <td id=\"T_bb875_row1_col12\" class=\"data row1 col12\" >-0.412995</td>\n",
       "      <td id=\"T_bb875_row1_col13\" class=\"data row1 col13\" >0.360445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb875_level0_row2\" class=\"row_heading level0 row2\" >INDUS</th>\n",
       "      <td id=\"T_bb875_row2_col0\" class=\"data row2 col0\" >0.406583</td>\n",
       "      <td id=\"T_bb875_row2_col1\" class=\"data row2 col1\" >-0.533828</td>\n",
       "      <td id=\"T_bb875_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "      <td id=\"T_bb875_row2_col3\" class=\"data row2 col3\" >0.062938</td>\n",
       "      <td id=\"T_bb875_row2_col4\" class=\"data row2 col4\" >0.763651</td>\n",
       "      <td id=\"T_bb875_row2_col5\" class=\"data row2 col5\" >-0.391676</td>\n",
       "      <td id=\"T_bb875_row2_col6\" class=\"data row2 col6\" >0.644779</td>\n",
       "      <td id=\"T_bb875_row2_col7\" class=\"data row2 col7\" >-0.708027</td>\n",
       "      <td id=\"T_bb875_row2_col8\" class=\"data row2 col8\" >0.595129</td>\n",
       "      <td id=\"T_bb875_row2_col9\" class=\"data row2 col9\" >0.720760</td>\n",
       "      <td id=\"T_bb875_row2_col10\" class=\"data row2 col10\" >0.383248</td>\n",
       "      <td id=\"T_bb875_row2_col11\" class=\"data row2 col11\" >-0.356977</td>\n",
       "      <td id=\"T_bb875_row2_col12\" class=\"data row2 col12\" >0.603800</td>\n",
       "      <td id=\"T_bb875_row2_col13\" class=\"data row2 col13\" >-0.483725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb875_level0_row3\" class=\"row_heading level0 row3\" >CHAS</th>\n",
       "      <td id=\"T_bb875_row3_col0\" class=\"data row3 col0\" >-0.055892</td>\n",
       "      <td id=\"T_bb875_row3_col1\" class=\"data row3 col1\" >-0.042697</td>\n",
       "      <td id=\"T_bb875_row3_col2\" class=\"data row3 col2\" >0.062938</td>\n",
       "      <td id=\"T_bb875_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "      <td id=\"T_bb875_row3_col4\" class=\"data row3 col4\" >0.091203</td>\n",
       "      <td id=\"T_bb875_row3_col5\" class=\"data row3 col5\" >0.091251</td>\n",
       "      <td id=\"T_bb875_row3_col6\" class=\"data row3 col6\" >0.086518</td>\n",
       "      <td id=\"T_bb875_row3_col7\" class=\"data row3 col7\" >-0.099176</td>\n",
       "      <td id=\"T_bb875_row3_col8\" class=\"data row3 col8\" >-0.007368</td>\n",
       "      <td id=\"T_bb875_row3_col9\" class=\"data row3 col9\" >-0.035587</td>\n",
       "      <td id=\"T_bb875_row3_col10\" class=\"data row3 col10\" >-0.121515</td>\n",
       "      <td id=\"T_bb875_row3_col11\" class=\"data row3 col11\" >0.048788</td>\n",
       "      <td id=\"T_bb875_row3_col12\" class=\"data row3 col12\" >-0.053929</td>\n",
       "      <td id=\"T_bb875_row3_col13\" class=\"data row3 col13\" >0.175260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb875_level0_row4\" class=\"row_heading level0 row4\" >NOX</th>\n",
       "      <td id=\"T_bb875_row4_col0\" class=\"data row4 col0\" >0.420972</td>\n",
       "      <td id=\"T_bb875_row4_col1\" class=\"data row4 col1\" >-0.516604</td>\n",
       "      <td id=\"T_bb875_row4_col2\" class=\"data row4 col2\" >0.763651</td>\n",
       "      <td id=\"T_bb875_row4_col3\" class=\"data row4 col3\" >0.091203</td>\n",
       "      <td id=\"T_bb875_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "      <td id=\"T_bb875_row4_col5\" class=\"data row4 col5\" >-0.302188</td>\n",
       "      <td id=\"T_bb875_row4_col6\" class=\"data row4 col6\" >0.731470</td>\n",
       "      <td id=\"T_bb875_row4_col7\" class=\"data row4 col7\" >-0.769230</td>\n",
       "      <td id=\"T_bb875_row4_col8\" class=\"data row4 col8\" >0.611441</td>\n",
       "      <td id=\"T_bb875_row4_col9\" class=\"data row4 col9\" >0.668023</td>\n",
       "      <td id=\"T_bb875_row4_col10\" class=\"data row4 col10\" >0.188933</td>\n",
       "      <td id=\"T_bb875_row4_col11\" class=\"data row4 col11\" >-0.380051</td>\n",
       "      <td id=\"T_bb875_row4_col12\" class=\"data row4 col12\" >0.590879</td>\n",
       "      <td id=\"T_bb875_row4_col13\" class=\"data row4 col13\" >-0.427321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb875_level0_row5\" class=\"row_heading level0 row5\" >RM</th>\n",
       "      <td id=\"T_bb875_row5_col0\" class=\"data row5 col0\" >-0.219247</td>\n",
       "      <td id=\"T_bb875_row5_col1\" class=\"data row5 col1\" >0.311991</td>\n",
       "      <td id=\"T_bb875_row5_col2\" class=\"data row5 col2\" >-0.391676</td>\n",
       "      <td id=\"T_bb875_row5_col3\" class=\"data row5 col3\" >0.091251</td>\n",
       "      <td id=\"T_bb875_row5_col4\" class=\"data row5 col4\" >-0.302188</td>\n",
       "      <td id=\"T_bb875_row5_col5\" class=\"data row5 col5\" >1.000000</td>\n",
       "      <td id=\"T_bb875_row5_col6\" class=\"data row5 col6\" >-0.240265</td>\n",
       "      <td id=\"T_bb875_row5_col7\" class=\"data row5 col7\" >0.205246</td>\n",
       "      <td id=\"T_bb875_row5_col8\" class=\"data row5 col8\" >-0.209847</td>\n",
       "      <td id=\"T_bb875_row5_col9\" class=\"data row5 col9\" >-0.292048</td>\n",
       "      <td id=\"T_bb875_row5_col10\" class=\"data row5 col10\" >-0.355501</td>\n",
       "      <td id=\"T_bb875_row5_col11\" class=\"data row5 col11\" >0.128069</td>\n",
       "      <td id=\"T_bb875_row5_col12\" class=\"data row5 col12\" >-0.613808</td>\n",
       "      <td id=\"T_bb875_row5_col13\" class=\"data row5 col13\" >0.695360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb875_level0_row6\" class=\"row_heading level0 row6\" >AGE</th>\n",
       "      <td id=\"T_bb875_row6_col0\" class=\"data row6 col0\" >0.352734</td>\n",
       "      <td id=\"T_bb875_row6_col1\" class=\"data row6 col1\" >-0.569537</td>\n",
       "      <td id=\"T_bb875_row6_col2\" class=\"data row6 col2\" >0.644779</td>\n",
       "      <td id=\"T_bb875_row6_col3\" class=\"data row6 col3\" >0.086518</td>\n",
       "      <td id=\"T_bb875_row6_col4\" class=\"data row6 col4\" >0.731470</td>\n",
       "      <td id=\"T_bb875_row6_col5\" class=\"data row6 col5\" >-0.240265</td>\n",
       "      <td id=\"T_bb875_row6_col6\" class=\"data row6 col6\" >1.000000</td>\n",
       "      <td id=\"T_bb875_row6_col7\" class=\"data row6 col7\" >-0.747881</td>\n",
       "      <td id=\"T_bb875_row6_col8\" class=\"data row6 col8\" >0.456022</td>\n",
       "      <td id=\"T_bb875_row6_col9\" class=\"data row6 col9\" >0.506456</td>\n",
       "      <td id=\"T_bb875_row6_col10\" class=\"data row6 col10\" >0.261515</td>\n",
       "      <td id=\"T_bb875_row6_col11\" class=\"data row6 col11\" >-0.273534</td>\n",
       "      <td id=\"T_bb875_row6_col12\" class=\"data row6 col12\" >0.602339</td>\n",
       "      <td id=\"T_bb875_row6_col13\" class=\"data row6 col13\" >-0.376955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb875_level0_row7\" class=\"row_heading level0 row7\" >DIS</th>\n",
       "      <td id=\"T_bb875_row7_col0\" class=\"data row7 col0\" >-0.379670</td>\n",
       "      <td id=\"T_bb875_row7_col1\" class=\"data row7 col1\" >0.664408</td>\n",
       "      <td id=\"T_bb875_row7_col2\" class=\"data row7 col2\" >-0.708027</td>\n",
       "      <td id=\"T_bb875_row7_col3\" class=\"data row7 col3\" >-0.099176</td>\n",
       "      <td id=\"T_bb875_row7_col4\" class=\"data row7 col4\" >-0.769230</td>\n",
       "      <td id=\"T_bb875_row7_col5\" class=\"data row7 col5\" >0.205246</td>\n",
       "      <td id=\"T_bb875_row7_col6\" class=\"data row7 col6\" >-0.747881</td>\n",
       "      <td id=\"T_bb875_row7_col7\" class=\"data row7 col7\" >1.000000</td>\n",
       "      <td id=\"T_bb875_row7_col8\" class=\"data row7 col8\" >-0.494588</td>\n",
       "      <td id=\"T_bb875_row7_col9\" class=\"data row7 col9\" >-0.534432</td>\n",
       "      <td id=\"T_bb875_row7_col10\" class=\"data row7 col10\" >-0.232471</td>\n",
       "      <td id=\"T_bb875_row7_col11\" class=\"data row7 col11\" >0.291512</td>\n",
       "      <td id=\"T_bb875_row7_col12\" class=\"data row7 col12\" >-0.496996</td>\n",
       "      <td id=\"T_bb875_row7_col13\" class=\"data row7 col13\" >0.249929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb875_level0_row8\" class=\"row_heading level0 row8\" >RAD</th>\n",
       "      <td id=\"T_bb875_row8_col0\" class=\"data row8 col0\" >0.625505</td>\n",
       "      <td id=\"T_bb875_row8_col1\" class=\"data row8 col1\" >-0.311948</td>\n",
       "      <td id=\"T_bb875_row8_col2\" class=\"data row8 col2\" >0.595129</td>\n",
       "      <td id=\"T_bb875_row8_col3\" class=\"data row8 col3\" >-0.007368</td>\n",
       "      <td id=\"T_bb875_row8_col4\" class=\"data row8 col4\" >0.611441</td>\n",
       "      <td id=\"T_bb875_row8_col5\" class=\"data row8 col5\" >-0.209847</td>\n",
       "      <td id=\"T_bb875_row8_col6\" class=\"data row8 col6\" >0.456022</td>\n",
       "      <td id=\"T_bb875_row8_col7\" class=\"data row8 col7\" >-0.494588</td>\n",
       "      <td id=\"T_bb875_row8_col8\" class=\"data row8 col8\" >1.000000</td>\n",
       "      <td id=\"T_bb875_row8_col9\" class=\"data row8 col9\" >0.910228</td>\n",
       "      <td id=\"T_bb875_row8_col10\" class=\"data row8 col10\" >0.464741</td>\n",
       "      <td id=\"T_bb875_row8_col11\" class=\"data row8 col11\" >-0.444413</td>\n",
       "      <td id=\"T_bb875_row8_col12\" class=\"data row8 col12\" >0.488676</td>\n",
       "      <td id=\"T_bb875_row8_col13\" class=\"data row8 col13\" >-0.381626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb875_level0_row9\" class=\"row_heading level0 row9\" >TAX</th>\n",
       "      <td id=\"T_bb875_row9_col0\" class=\"data row9 col0\" >0.582764</td>\n",
       "      <td id=\"T_bb875_row9_col1\" class=\"data row9 col1\" >-0.314563</td>\n",
       "      <td id=\"T_bb875_row9_col2\" class=\"data row9 col2\" >0.720760</td>\n",
       "      <td id=\"T_bb875_row9_col3\" class=\"data row9 col3\" >-0.035587</td>\n",
       "      <td id=\"T_bb875_row9_col4\" class=\"data row9 col4\" >0.668023</td>\n",
       "      <td id=\"T_bb875_row9_col5\" class=\"data row9 col5\" >-0.292048</td>\n",
       "      <td id=\"T_bb875_row9_col6\" class=\"data row9 col6\" >0.506456</td>\n",
       "      <td id=\"T_bb875_row9_col7\" class=\"data row9 col7\" >-0.534432</td>\n",
       "      <td id=\"T_bb875_row9_col8\" class=\"data row9 col8\" >0.910228</td>\n",
       "      <td id=\"T_bb875_row9_col9\" class=\"data row9 col9\" >1.000000</td>\n",
       "      <td id=\"T_bb875_row9_col10\" class=\"data row9 col10\" >0.460853</td>\n",
       "      <td id=\"T_bb875_row9_col11\" class=\"data row9 col11\" >-0.441808</td>\n",
       "      <td id=\"T_bb875_row9_col12\" class=\"data row9 col12\" >0.543993</td>\n",
       "      <td id=\"T_bb875_row9_col13\" class=\"data row9 col13\" >-0.468536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb875_level0_row10\" class=\"row_heading level0 row10\" >PTRATIO</th>\n",
       "      <td id=\"T_bb875_row10_col0\" class=\"data row10 col0\" >0.289946</td>\n",
       "      <td id=\"T_bb875_row10_col1\" class=\"data row10 col1\" >-0.391679</td>\n",
       "      <td id=\"T_bb875_row10_col2\" class=\"data row10 col2\" >0.383248</td>\n",
       "      <td id=\"T_bb875_row10_col3\" class=\"data row10 col3\" >-0.121515</td>\n",
       "      <td id=\"T_bb875_row10_col4\" class=\"data row10 col4\" >0.188933</td>\n",
       "      <td id=\"T_bb875_row10_col5\" class=\"data row10 col5\" >-0.355501</td>\n",
       "      <td id=\"T_bb875_row10_col6\" class=\"data row10 col6\" >0.261515</td>\n",
       "      <td id=\"T_bb875_row10_col7\" class=\"data row10 col7\" >-0.232471</td>\n",
       "      <td id=\"T_bb875_row10_col8\" class=\"data row10 col8\" >0.464741</td>\n",
       "      <td id=\"T_bb875_row10_col9\" class=\"data row10 col9\" >0.460853</td>\n",
       "      <td id=\"T_bb875_row10_col10\" class=\"data row10 col10\" >1.000000</td>\n",
       "      <td id=\"T_bb875_row10_col11\" class=\"data row10 col11\" >-0.177383</td>\n",
       "      <td id=\"T_bb875_row10_col12\" class=\"data row10 col12\" >0.374044</td>\n",
       "      <td id=\"T_bb875_row10_col13\" class=\"data row10 col13\" >-0.507787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb875_level0_row11\" class=\"row_heading level0 row11\" >B</th>\n",
       "      <td id=\"T_bb875_row11_col0\" class=\"data row11 col0\" >-0.385064</td>\n",
       "      <td id=\"T_bb875_row11_col1\" class=\"data row11 col1\" >0.175520</td>\n",
       "      <td id=\"T_bb875_row11_col2\" class=\"data row11 col2\" >-0.356977</td>\n",
       "      <td id=\"T_bb875_row11_col3\" class=\"data row11 col3\" >0.048788</td>\n",
       "      <td id=\"T_bb875_row11_col4\" class=\"data row11 col4\" >-0.380051</td>\n",
       "      <td id=\"T_bb875_row11_col5\" class=\"data row11 col5\" >0.128069</td>\n",
       "      <td id=\"T_bb875_row11_col6\" class=\"data row11 col6\" >-0.273534</td>\n",
       "      <td id=\"T_bb875_row11_col7\" class=\"data row11 col7\" >0.291512</td>\n",
       "      <td id=\"T_bb875_row11_col8\" class=\"data row11 col8\" >-0.444413</td>\n",
       "      <td id=\"T_bb875_row11_col9\" class=\"data row11 col9\" >-0.441808</td>\n",
       "      <td id=\"T_bb875_row11_col10\" class=\"data row11 col10\" >-0.177383</td>\n",
       "      <td id=\"T_bb875_row11_col11\" class=\"data row11 col11\" >1.000000</td>\n",
       "      <td id=\"T_bb875_row11_col12\" class=\"data row11 col12\" >-0.366087</td>\n",
       "      <td id=\"T_bb875_row11_col13\" class=\"data row11 col13\" >0.333461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb875_level0_row12\" class=\"row_heading level0 row12\" >LSTAT</th>\n",
       "      <td id=\"T_bb875_row12_col0\" class=\"data row12 col0\" >0.455621</td>\n",
       "      <td id=\"T_bb875_row12_col1\" class=\"data row12 col1\" >-0.412995</td>\n",
       "      <td id=\"T_bb875_row12_col2\" class=\"data row12 col2\" >0.603800</td>\n",
       "      <td id=\"T_bb875_row12_col3\" class=\"data row12 col3\" >-0.053929</td>\n",
       "      <td id=\"T_bb875_row12_col4\" class=\"data row12 col4\" >0.590879</td>\n",
       "      <td id=\"T_bb875_row12_col5\" class=\"data row12 col5\" >-0.613808</td>\n",
       "      <td id=\"T_bb875_row12_col6\" class=\"data row12 col6\" >0.602339</td>\n",
       "      <td id=\"T_bb875_row12_col7\" class=\"data row12 col7\" >-0.496996</td>\n",
       "      <td id=\"T_bb875_row12_col8\" class=\"data row12 col8\" >0.488676</td>\n",
       "      <td id=\"T_bb875_row12_col9\" class=\"data row12 col9\" >0.543993</td>\n",
       "      <td id=\"T_bb875_row12_col10\" class=\"data row12 col10\" >0.374044</td>\n",
       "      <td id=\"T_bb875_row12_col11\" class=\"data row12 col11\" >-0.366087</td>\n",
       "      <td id=\"T_bb875_row12_col12\" class=\"data row12 col12\" >1.000000</td>\n",
       "      <td id=\"T_bb875_row12_col13\" class=\"data row12 col13\" >-0.737663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb875_level0_row13\" class=\"row_heading level0 row13\" >target</th>\n",
       "      <td id=\"T_bb875_row13_col0\" class=\"data row13 col0\" >-0.388305</td>\n",
       "      <td id=\"T_bb875_row13_col1\" class=\"data row13 col1\" >0.360445</td>\n",
       "      <td id=\"T_bb875_row13_col2\" class=\"data row13 col2\" >-0.483725</td>\n",
       "      <td id=\"T_bb875_row13_col3\" class=\"data row13 col3\" >0.175260</td>\n",
       "      <td id=\"T_bb875_row13_col4\" class=\"data row13 col4\" >-0.427321</td>\n",
       "      <td id=\"T_bb875_row13_col5\" class=\"data row13 col5\" >0.695360</td>\n",
       "      <td id=\"T_bb875_row13_col6\" class=\"data row13 col6\" >-0.376955</td>\n",
       "      <td id=\"T_bb875_row13_col7\" class=\"data row13 col7\" >0.249929</td>\n",
       "      <td id=\"T_bb875_row13_col8\" class=\"data row13 col8\" >-0.381626</td>\n",
       "      <td id=\"T_bb875_row13_col9\" class=\"data row13 col9\" >-0.468536</td>\n",
       "      <td id=\"T_bb875_row13_col10\" class=\"data row13 col10\" >-0.507787</td>\n",
       "      <td id=\"T_bb875_row13_col11\" class=\"data row13 col11\" >0.333461</td>\n",
       "      <td id=\"T_bb875_row13_col12\" class=\"data row13 col12\" >-0.737663</td>\n",
       "      <td id=\"T_bb875_row13_col13\" class=\"data row13 col13\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23595be3130>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.style.applymap(colour_large_values_red)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see a high correlation between the RAD and TAX variables. This is quite interesting, as the variables themselves are not-obviously so related. Here is what the dataset's description has to say:\n",
    "\n",
    "\n",
    "        - RAD      index of accessibility to radial highways\n",
    "        - TAX      full-value property-tax rate per $10,000\n",
    "\n",
    "So it appears that a high accessibility to the highway results in a higher property tax rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercises\n",
    "\n",
    "1. Train a linear model using just the RAD and TAX variables, and examine the beta values. Train another two, this time using just RAD and another using just TAX. Note the difference in the beta values, indicating that the linear relationship was getting in the way of the linear model.\n",
    "2. Create a dataset with two independent variables ($X_1$ and $X_2$) and a dependent variable $Y$ with the following properties. What does the pairwise correlation look like, and how does this affect the linear regression model?\n",
    "    - $X_1$ has a high correlation to $Y$ \n",
    "    - $X_2$ has a high correlation to $Y$\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   R-squared:                       0.231\n",
      "Model:                            OLS   Adj. R-squared:                  0.228\n",
      "Method:                 Least Squares   F-statistic:                     75.66\n",
      "Date:                Tue, 03 Jan 2023   Prob (F-statistic):           1.88e-29\n",
      "Time:                        16:35:01   Log-Likelihood:                -1773.7\n",
      "No. Observations:                 506   AIC:                             3553.\n",
      "Df Residuals:                     503   BIC:                             3566.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     35.6359      1.347     26.465      0.000      32.990      38.281\n",
      "RAD            0.2762      0.100      2.770      0.006       0.080       0.472\n",
      "TAX           -0.0386      0.005     -7.485      0.000      -0.049      -0.028\n",
      "==============================================================================\n",
      "Omnibus:                      170.143   Durbin-Watson:                   0.648\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              486.175\n",
      "Skew:                           1.637   Prob(JB):                    2.68e-106\n",
      "Kurtosis:                       6.513   Cond. No.                     1.66e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.66e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# both rad and tax\n",
    "formula1 = \"target ~ RAD + TAX\"\n",
    "model1 = smf.ols(formula=formula1, data=boston).fit()\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   R-squared:                       0.146\n",
      "Model:                            OLS   Adj. R-squared:                  0.144\n",
      "Method:                 Least Squares   F-statistic:                     85.91\n",
      "Date:                Tue, 03 Jan 2023   Prob (F-statistic):           5.47e-19\n",
      "Time:                        16:35:08   Log-Likelihood:                -1800.4\n",
      "No. Observations:                 506   AIC:                             3605.\n",
      "Df Residuals:                     504   BIC:                             3613.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     26.3821      0.562     46.964      0.000      25.278      27.486\n",
      "RAD           -0.4031      0.043     -9.269      0.000      -0.489      -0.318\n",
      "==============================================================================\n",
      "Omnibus:                      149.634   Durbin-Watson:                   0.632\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              359.231\n",
      "Skew:                           1.515   Prob(JB):                     9.86e-79\n",
      "Kurtosis:                       5.803   Cond. No.                         19.2\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# only rad\n",
    "formula2 = \"target ~ RAD\"\n",
    "model2 = smf.ols(formula=formula2, data=boston).fit()\n",
    "print(model2.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   R-squared:                       0.220\n",
      "Model:                            OLS   Adj. R-squared:                  0.218\n",
      "Method:                 Least Squares   F-statistic:                     141.8\n",
      "Date:                Tue, 03 Jan 2023   Prob (F-statistic):           5.64e-29\n",
      "Time:                        16:35:10   Log-Likelihood:                -1777.5\n",
      "No. Observations:                 506   AIC:                             3559.\n",
      "Df Residuals:                     504   BIC:                             3568.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     32.9707      0.948     34.768      0.000      31.108      34.834\n",
      "TAX           -0.0256      0.002    -11.906      0.000      -0.030      -0.021\n",
      "==============================================================================\n",
      "Omnibus:                      172.501   Durbin-Watson:                   0.648\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              494.072\n",
      "Skew:                           1.661   Prob(JB):                    5.17e-108\n",
      "Kurtosis:                       6.521   Cond. No.                     1.16e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.16e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# only tax\n",
    "formula3 = \"target ~ TAX\"\n",
    "model3 = smf.ols(formula=formula3, data=boston).fit()\n",
    "print(model3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>Y</td>        <th>  R-squared:         </th>  <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>2.361e+32</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 03 Jan 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:51:45</td>     <th>  Log-Likelihood:    </th>  <td>  33648.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1000</td>      <th>  AIC:               </th> <td>-6.729e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   998</td>      <th>  BIC:               </th> <td>-6.728e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -0.9677</td> <td> 8.31e-17</td> <td>-1.17e+16</td> <td> 0.000</td> <td>   -0.968</td> <td>   -0.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X1</th>        <td>    0.1935</td> <td> 1.01e-17</td> <td> 1.92e+16</td> <td> 0.000</td> <td>    0.194</td> <td>    0.194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X2</th>        <td>    0.8387</td> <td> 7.08e-17</td> <td> 1.18e+16</td> <td> 0.000</td> <td>    0.839</td> <td>    0.839</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>10.949</td> <th>  Durbin-Watson:     </th> <td>   0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.004</td> <th>  Jarque-Bera (JB):  </th> <td>   7.297</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.041</td> <th>  Prob(JB):          </th> <td>  0.0260</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.590</td> <th>  Cond. No.          </th> <td>8.83e+15</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 5.63e-28. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      Y   R-squared:                       1.000\n",
       "Model:                            OLS   Adj. R-squared:                  1.000\n",
       "Method:                 Least Squares   F-statistic:                 2.361e+32\n",
       "Date:                Tue, 03 Jan 2023   Prob (F-statistic):               0.00\n",
       "Time:                        16:51:45   Log-Likelihood:                 33648.\n",
       "No. Observations:                1000   AIC:                        -6.729e+04\n",
       "Df Residuals:                     998   BIC:                        -6.728e+04\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -0.9677   8.31e-17  -1.17e+16      0.000      -0.968      -0.968\n",
       "X1             0.1935   1.01e-17   1.92e+16      0.000       0.194       0.194\n",
       "X2             0.8387   7.08e-17   1.18e+16      0.000       0.839       0.839\n",
       "==============================================================================\n",
       "Omnibus:                       10.949   Durbin-Watson:                   0.043\n",
       "Prob(Omnibus):                  0.004   Jarque-Bera (JB):                7.297\n",
       "Skew:                          -0.041   Prob(JB):                       0.0260\n",
       "Kurtosis:                       2.590   Cond. No.                     8.83e+15\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 5.63e-28. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create random distribution\n",
    "Y = np.random.random(1000)\n",
    "\n",
    "# create 2 variables  which correlate with Y\n",
    "X1 = Y * 3 + 5\n",
    "X2 = Y / 2\n",
    "\n",
    "# run regression\n",
    "data = pd.Series({\"X1\": X1, \"X2\": X2, \"Y\": Y})\n",
    "est_corr = smf.ols(formula=\"Y ~ X1 + X2\", data=data).fit()\n",
    "est_corr.summary()\n",
    "\n",
    "# we can see the sum of beta sums to almost 1, meaning their combined contribution\n",
    "# to Y shows that there is an interaction. It also shows that it results in a very \n",
    "# good fit as seen from the R^2 and adjusted R^2 values. We can also seen that\n",
    "# the variables have high significance as we already know these variables are\n",
    "# directly related"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For solutions, see `solutions/correlations.py`*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multicolinearity\n",
    "\n",
    "Multicolinearity is simply the case where there are **multi**ple **colinearities** in the dataset - that is, many of the variables are related. In this case, the affect on the result is usually higher and may affect the model more. However, the process for managing stays the same as the points mentioned above.\n",
    "\n",
    "It is also worth noting that multicolinearity and colinearity, at least in the practical sense, are *degrees* and not absolutes. A variable may have lesser or greater colinearity, but there is no threshold above which we say that the colinearity exists. Usually, we would say values above 0.9 definitely have it, and values lesser may have it.\n",
    "\n",
    "For instance, we can repeat the above table to suddenly \"observe multicolinearity\":\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_43fc7_row0_col0, #T_43fc7_row1_col1, #T_43fc7_row2_col2, #T_43fc7_row2_col4, #T_43fc7_row2_col7, #T_43fc7_row2_col9, #T_43fc7_row3_col3, #T_43fc7_row4_col2, #T_43fc7_row4_col4, #T_43fc7_row4_col6, #T_43fc7_row4_col7, #T_43fc7_row5_col5, #T_43fc7_row6_col4, #T_43fc7_row6_col6, #T_43fc7_row6_col7, #T_43fc7_row7_col2, #T_43fc7_row7_col4, #T_43fc7_row7_col6, #T_43fc7_row7_col7, #T_43fc7_row8_col8, #T_43fc7_row8_col9, #T_43fc7_row9_col2, #T_43fc7_row9_col8, #T_43fc7_row9_col9, #T_43fc7_row10_col10, #T_43fc7_row11_col11, #T_43fc7_row12_col12, #T_43fc7_row12_col13, #T_43fc7_row13_col12, #T_43fc7_row13_col13 {\n",
       "  background-color: red;\n",
       "}\n",
       "#T_43fc7_row0_col1, #T_43fc7_row0_col2, #T_43fc7_row0_col3, #T_43fc7_row0_col4, #T_43fc7_row0_col5, #T_43fc7_row0_col6, #T_43fc7_row0_col7, #T_43fc7_row0_col8, #T_43fc7_row0_col9, #T_43fc7_row0_col10, #T_43fc7_row0_col11, #T_43fc7_row0_col12, #T_43fc7_row0_col13, #T_43fc7_row1_col0, #T_43fc7_row1_col2, #T_43fc7_row1_col3, #T_43fc7_row1_col4, #T_43fc7_row1_col5, #T_43fc7_row1_col6, #T_43fc7_row1_col7, #T_43fc7_row1_col8, #T_43fc7_row1_col9, #T_43fc7_row1_col10, #T_43fc7_row1_col11, #T_43fc7_row1_col12, #T_43fc7_row1_col13, #T_43fc7_row2_col0, #T_43fc7_row2_col1, #T_43fc7_row2_col3, #T_43fc7_row2_col5, #T_43fc7_row2_col6, #T_43fc7_row2_col8, #T_43fc7_row2_col10, #T_43fc7_row2_col11, #T_43fc7_row2_col12, #T_43fc7_row2_col13, #T_43fc7_row3_col0, #T_43fc7_row3_col1, #T_43fc7_row3_col2, #T_43fc7_row3_col4, #T_43fc7_row3_col5, #T_43fc7_row3_col6, #T_43fc7_row3_col7, #T_43fc7_row3_col8, #T_43fc7_row3_col9, #T_43fc7_row3_col10, #T_43fc7_row3_col11, #T_43fc7_row3_col12, #T_43fc7_row3_col13, #T_43fc7_row4_col0, #T_43fc7_row4_col1, #T_43fc7_row4_col3, #T_43fc7_row4_col5, #T_43fc7_row4_col8, #T_43fc7_row4_col9, #T_43fc7_row4_col10, #T_43fc7_row4_col11, #T_43fc7_row4_col12, #T_43fc7_row4_col13, #T_43fc7_row5_col0, #T_43fc7_row5_col1, #T_43fc7_row5_col2, #T_43fc7_row5_col3, #T_43fc7_row5_col4, #T_43fc7_row5_col6, #T_43fc7_row5_col7, #T_43fc7_row5_col8, #T_43fc7_row5_col9, #T_43fc7_row5_col10, #T_43fc7_row5_col11, #T_43fc7_row5_col12, #T_43fc7_row5_col13, #T_43fc7_row6_col0, #T_43fc7_row6_col1, #T_43fc7_row6_col2, #T_43fc7_row6_col3, #T_43fc7_row6_col5, #T_43fc7_row6_col8, #T_43fc7_row6_col9, #T_43fc7_row6_col10, #T_43fc7_row6_col11, #T_43fc7_row6_col12, #T_43fc7_row6_col13, #T_43fc7_row7_col0, #T_43fc7_row7_col1, #T_43fc7_row7_col3, #T_43fc7_row7_col5, #T_43fc7_row7_col8, #T_43fc7_row7_col9, #T_43fc7_row7_col10, #T_43fc7_row7_col11, #T_43fc7_row7_col12, #T_43fc7_row7_col13, #T_43fc7_row8_col0, #T_43fc7_row8_col1, #T_43fc7_row8_col2, #T_43fc7_row8_col3, #T_43fc7_row8_col4, #T_43fc7_row8_col5, #T_43fc7_row8_col6, #T_43fc7_row8_col7, #T_43fc7_row8_col10, #T_43fc7_row8_col11, #T_43fc7_row8_col12, #T_43fc7_row8_col13, #T_43fc7_row9_col0, #T_43fc7_row9_col1, #T_43fc7_row9_col3, #T_43fc7_row9_col4, #T_43fc7_row9_col5, #T_43fc7_row9_col6, #T_43fc7_row9_col7, #T_43fc7_row9_col10, #T_43fc7_row9_col11, #T_43fc7_row9_col12, #T_43fc7_row9_col13, #T_43fc7_row10_col0, #T_43fc7_row10_col1, #T_43fc7_row10_col2, #T_43fc7_row10_col3, #T_43fc7_row10_col4, #T_43fc7_row10_col5, #T_43fc7_row10_col6, #T_43fc7_row10_col7, #T_43fc7_row10_col8, #T_43fc7_row10_col9, #T_43fc7_row10_col11, #T_43fc7_row10_col12, #T_43fc7_row10_col13, #T_43fc7_row11_col0, #T_43fc7_row11_col1, #T_43fc7_row11_col2, #T_43fc7_row11_col3, #T_43fc7_row11_col4, #T_43fc7_row11_col5, #T_43fc7_row11_col6, #T_43fc7_row11_col7, #T_43fc7_row11_col8, #T_43fc7_row11_col9, #T_43fc7_row11_col10, #T_43fc7_row11_col12, #T_43fc7_row11_col13, #T_43fc7_row12_col0, #T_43fc7_row12_col1, #T_43fc7_row12_col2, #T_43fc7_row12_col3, #T_43fc7_row12_col4, #T_43fc7_row12_col5, #T_43fc7_row12_col6, #T_43fc7_row12_col7, #T_43fc7_row12_col8, #T_43fc7_row12_col9, #T_43fc7_row12_col10, #T_43fc7_row12_col11, #T_43fc7_row13_col0, #T_43fc7_row13_col1, #T_43fc7_row13_col2, #T_43fc7_row13_col3, #T_43fc7_row13_col4, #T_43fc7_row13_col5, #T_43fc7_row13_col6, #T_43fc7_row13_col7, #T_43fc7_row13_col8, #T_43fc7_row13_col9, #T_43fc7_row13_col10, #T_43fc7_row13_col11 {\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_43fc7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_43fc7_level0_col0\" class=\"col_heading level0 col0\" >CRIM</th>\n",
       "      <th id=\"T_43fc7_level0_col1\" class=\"col_heading level0 col1\" >ZN</th>\n",
       "      <th id=\"T_43fc7_level0_col2\" class=\"col_heading level0 col2\" >INDUS</th>\n",
       "      <th id=\"T_43fc7_level0_col3\" class=\"col_heading level0 col3\" >CHAS</th>\n",
       "      <th id=\"T_43fc7_level0_col4\" class=\"col_heading level0 col4\" >NOX</th>\n",
       "      <th id=\"T_43fc7_level0_col5\" class=\"col_heading level0 col5\" >RM</th>\n",
       "      <th id=\"T_43fc7_level0_col6\" class=\"col_heading level0 col6\" >AGE</th>\n",
       "      <th id=\"T_43fc7_level0_col7\" class=\"col_heading level0 col7\" >DIS</th>\n",
       "      <th id=\"T_43fc7_level0_col8\" class=\"col_heading level0 col8\" >RAD</th>\n",
       "      <th id=\"T_43fc7_level0_col9\" class=\"col_heading level0 col9\" >TAX</th>\n",
       "      <th id=\"T_43fc7_level0_col10\" class=\"col_heading level0 col10\" >PTRATIO</th>\n",
       "      <th id=\"T_43fc7_level0_col11\" class=\"col_heading level0 col11\" >B</th>\n",
       "      <th id=\"T_43fc7_level0_col12\" class=\"col_heading level0 col12\" >LSTAT</th>\n",
       "      <th id=\"T_43fc7_level0_col13\" class=\"col_heading level0 col13\" >target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_43fc7_level0_row0\" class=\"row_heading level0 row0\" >CRIM</th>\n",
       "      <td id=\"T_43fc7_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "      <td id=\"T_43fc7_row0_col1\" class=\"data row0 col1\" >-0.200469</td>\n",
       "      <td id=\"T_43fc7_row0_col2\" class=\"data row0 col2\" >0.406583</td>\n",
       "      <td id=\"T_43fc7_row0_col3\" class=\"data row0 col3\" >-0.055892</td>\n",
       "      <td id=\"T_43fc7_row0_col4\" class=\"data row0 col4\" >0.420972</td>\n",
       "      <td id=\"T_43fc7_row0_col5\" class=\"data row0 col5\" >-0.219247</td>\n",
       "      <td id=\"T_43fc7_row0_col6\" class=\"data row0 col6\" >0.352734</td>\n",
       "      <td id=\"T_43fc7_row0_col7\" class=\"data row0 col7\" >-0.379670</td>\n",
       "      <td id=\"T_43fc7_row0_col8\" class=\"data row0 col8\" >0.625505</td>\n",
       "      <td id=\"T_43fc7_row0_col9\" class=\"data row0 col9\" >0.582764</td>\n",
       "      <td id=\"T_43fc7_row0_col10\" class=\"data row0 col10\" >0.289946</td>\n",
       "      <td id=\"T_43fc7_row0_col11\" class=\"data row0 col11\" >-0.385064</td>\n",
       "      <td id=\"T_43fc7_row0_col12\" class=\"data row0 col12\" >0.455621</td>\n",
       "      <td id=\"T_43fc7_row0_col13\" class=\"data row0 col13\" >-0.388305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43fc7_level0_row1\" class=\"row_heading level0 row1\" >ZN</th>\n",
       "      <td id=\"T_43fc7_row1_col0\" class=\"data row1 col0\" >-0.200469</td>\n",
       "      <td id=\"T_43fc7_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "      <td id=\"T_43fc7_row1_col2\" class=\"data row1 col2\" >-0.533828</td>\n",
       "      <td id=\"T_43fc7_row1_col3\" class=\"data row1 col3\" >-0.042697</td>\n",
       "      <td id=\"T_43fc7_row1_col4\" class=\"data row1 col4\" >-0.516604</td>\n",
       "      <td id=\"T_43fc7_row1_col5\" class=\"data row1 col5\" >0.311991</td>\n",
       "      <td id=\"T_43fc7_row1_col6\" class=\"data row1 col6\" >-0.569537</td>\n",
       "      <td id=\"T_43fc7_row1_col7\" class=\"data row1 col7\" >0.664408</td>\n",
       "      <td id=\"T_43fc7_row1_col8\" class=\"data row1 col8\" >-0.311948</td>\n",
       "      <td id=\"T_43fc7_row1_col9\" class=\"data row1 col9\" >-0.314563</td>\n",
       "      <td id=\"T_43fc7_row1_col10\" class=\"data row1 col10\" >-0.391679</td>\n",
       "      <td id=\"T_43fc7_row1_col11\" class=\"data row1 col11\" >0.175520</td>\n",
       "      <td id=\"T_43fc7_row1_col12\" class=\"data row1 col12\" >-0.412995</td>\n",
       "      <td id=\"T_43fc7_row1_col13\" class=\"data row1 col13\" >0.360445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43fc7_level0_row2\" class=\"row_heading level0 row2\" >INDUS</th>\n",
       "      <td id=\"T_43fc7_row2_col0\" class=\"data row2 col0\" >0.406583</td>\n",
       "      <td id=\"T_43fc7_row2_col1\" class=\"data row2 col1\" >-0.533828</td>\n",
       "      <td id=\"T_43fc7_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "      <td id=\"T_43fc7_row2_col3\" class=\"data row2 col3\" >0.062938</td>\n",
       "      <td id=\"T_43fc7_row2_col4\" class=\"data row2 col4\" >0.763651</td>\n",
       "      <td id=\"T_43fc7_row2_col5\" class=\"data row2 col5\" >-0.391676</td>\n",
       "      <td id=\"T_43fc7_row2_col6\" class=\"data row2 col6\" >0.644779</td>\n",
       "      <td id=\"T_43fc7_row2_col7\" class=\"data row2 col7\" >-0.708027</td>\n",
       "      <td id=\"T_43fc7_row2_col8\" class=\"data row2 col8\" >0.595129</td>\n",
       "      <td id=\"T_43fc7_row2_col9\" class=\"data row2 col9\" >0.720760</td>\n",
       "      <td id=\"T_43fc7_row2_col10\" class=\"data row2 col10\" >0.383248</td>\n",
       "      <td id=\"T_43fc7_row2_col11\" class=\"data row2 col11\" >-0.356977</td>\n",
       "      <td id=\"T_43fc7_row2_col12\" class=\"data row2 col12\" >0.603800</td>\n",
       "      <td id=\"T_43fc7_row2_col13\" class=\"data row2 col13\" >-0.483725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43fc7_level0_row3\" class=\"row_heading level0 row3\" >CHAS</th>\n",
       "      <td id=\"T_43fc7_row3_col0\" class=\"data row3 col0\" >-0.055892</td>\n",
       "      <td id=\"T_43fc7_row3_col1\" class=\"data row3 col1\" >-0.042697</td>\n",
       "      <td id=\"T_43fc7_row3_col2\" class=\"data row3 col2\" >0.062938</td>\n",
       "      <td id=\"T_43fc7_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "      <td id=\"T_43fc7_row3_col4\" class=\"data row3 col4\" >0.091203</td>\n",
       "      <td id=\"T_43fc7_row3_col5\" class=\"data row3 col5\" >0.091251</td>\n",
       "      <td id=\"T_43fc7_row3_col6\" class=\"data row3 col6\" >0.086518</td>\n",
       "      <td id=\"T_43fc7_row3_col7\" class=\"data row3 col7\" >-0.099176</td>\n",
       "      <td id=\"T_43fc7_row3_col8\" class=\"data row3 col8\" >-0.007368</td>\n",
       "      <td id=\"T_43fc7_row3_col9\" class=\"data row3 col9\" >-0.035587</td>\n",
       "      <td id=\"T_43fc7_row3_col10\" class=\"data row3 col10\" >-0.121515</td>\n",
       "      <td id=\"T_43fc7_row3_col11\" class=\"data row3 col11\" >0.048788</td>\n",
       "      <td id=\"T_43fc7_row3_col12\" class=\"data row3 col12\" >-0.053929</td>\n",
       "      <td id=\"T_43fc7_row3_col13\" class=\"data row3 col13\" >0.175260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43fc7_level0_row4\" class=\"row_heading level0 row4\" >NOX</th>\n",
       "      <td id=\"T_43fc7_row4_col0\" class=\"data row4 col0\" >0.420972</td>\n",
       "      <td id=\"T_43fc7_row4_col1\" class=\"data row4 col1\" >-0.516604</td>\n",
       "      <td id=\"T_43fc7_row4_col2\" class=\"data row4 col2\" >0.763651</td>\n",
       "      <td id=\"T_43fc7_row4_col3\" class=\"data row4 col3\" >0.091203</td>\n",
       "      <td id=\"T_43fc7_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "      <td id=\"T_43fc7_row4_col5\" class=\"data row4 col5\" >-0.302188</td>\n",
       "      <td id=\"T_43fc7_row4_col6\" class=\"data row4 col6\" >0.731470</td>\n",
       "      <td id=\"T_43fc7_row4_col7\" class=\"data row4 col7\" >-0.769230</td>\n",
       "      <td id=\"T_43fc7_row4_col8\" class=\"data row4 col8\" >0.611441</td>\n",
       "      <td id=\"T_43fc7_row4_col9\" class=\"data row4 col9\" >0.668023</td>\n",
       "      <td id=\"T_43fc7_row4_col10\" class=\"data row4 col10\" >0.188933</td>\n",
       "      <td id=\"T_43fc7_row4_col11\" class=\"data row4 col11\" >-0.380051</td>\n",
       "      <td id=\"T_43fc7_row4_col12\" class=\"data row4 col12\" >0.590879</td>\n",
       "      <td id=\"T_43fc7_row4_col13\" class=\"data row4 col13\" >-0.427321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43fc7_level0_row5\" class=\"row_heading level0 row5\" >RM</th>\n",
       "      <td id=\"T_43fc7_row5_col0\" class=\"data row5 col0\" >-0.219247</td>\n",
       "      <td id=\"T_43fc7_row5_col1\" class=\"data row5 col1\" >0.311991</td>\n",
       "      <td id=\"T_43fc7_row5_col2\" class=\"data row5 col2\" >-0.391676</td>\n",
       "      <td id=\"T_43fc7_row5_col3\" class=\"data row5 col3\" >0.091251</td>\n",
       "      <td id=\"T_43fc7_row5_col4\" class=\"data row5 col4\" >-0.302188</td>\n",
       "      <td id=\"T_43fc7_row5_col5\" class=\"data row5 col5\" >1.000000</td>\n",
       "      <td id=\"T_43fc7_row5_col6\" class=\"data row5 col6\" >-0.240265</td>\n",
       "      <td id=\"T_43fc7_row5_col7\" class=\"data row5 col7\" >0.205246</td>\n",
       "      <td id=\"T_43fc7_row5_col8\" class=\"data row5 col8\" >-0.209847</td>\n",
       "      <td id=\"T_43fc7_row5_col9\" class=\"data row5 col9\" >-0.292048</td>\n",
       "      <td id=\"T_43fc7_row5_col10\" class=\"data row5 col10\" >-0.355501</td>\n",
       "      <td id=\"T_43fc7_row5_col11\" class=\"data row5 col11\" >0.128069</td>\n",
       "      <td id=\"T_43fc7_row5_col12\" class=\"data row5 col12\" >-0.613808</td>\n",
       "      <td id=\"T_43fc7_row5_col13\" class=\"data row5 col13\" >0.695360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43fc7_level0_row6\" class=\"row_heading level0 row6\" >AGE</th>\n",
       "      <td id=\"T_43fc7_row6_col0\" class=\"data row6 col0\" >0.352734</td>\n",
       "      <td id=\"T_43fc7_row6_col1\" class=\"data row6 col1\" >-0.569537</td>\n",
       "      <td id=\"T_43fc7_row6_col2\" class=\"data row6 col2\" >0.644779</td>\n",
       "      <td id=\"T_43fc7_row6_col3\" class=\"data row6 col3\" >0.086518</td>\n",
       "      <td id=\"T_43fc7_row6_col4\" class=\"data row6 col4\" >0.731470</td>\n",
       "      <td id=\"T_43fc7_row6_col5\" class=\"data row6 col5\" >-0.240265</td>\n",
       "      <td id=\"T_43fc7_row6_col6\" class=\"data row6 col6\" >1.000000</td>\n",
       "      <td id=\"T_43fc7_row6_col7\" class=\"data row6 col7\" >-0.747881</td>\n",
       "      <td id=\"T_43fc7_row6_col8\" class=\"data row6 col8\" >0.456022</td>\n",
       "      <td id=\"T_43fc7_row6_col9\" class=\"data row6 col9\" >0.506456</td>\n",
       "      <td id=\"T_43fc7_row6_col10\" class=\"data row6 col10\" >0.261515</td>\n",
       "      <td id=\"T_43fc7_row6_col11\" class=\"data row6 col11\" >-0.273534</td>\n",
       "      <td id=\"T_43fc7_row6_col12\" class=\"data row6 col12\" >0.602339</td>\n",
       "      <td id=\"T_43fc7_row6_col13\" class=\"data row6 col13\" >-0.376955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43fc7_level0_row7\" class=\"row_heading level0 row7\" >DIS</th>\n",
       "      <td id=\"T_43fc7_row7_col0\" class=\"data row7 col0\" >-0.379670</td>\n",
       "      <td id=\"T_43fc7_row7_col1\" class=\"data row7 col1\" >0.664408</td>\n",
       "      <td id=\"T_43fc7_row7_col2\" class=\"data row7 col2\" >-0.708027</td>\n",
       "      <td id=\"T_43fc7_row7_col3\" class=\"data row7 col3\" >-0.099176</td>\n",
       "      <td id=\"T_43fc7_row7_col4\" class=\"data row7 col4\" >-0.769230</td>\n",
       "      <td id=\"T_43fc7_row7_col5\" class=\"data row7 col5\" >0.205246</td>\n",
       "      <td id=\"T_43fc7_row7_col6\" class=\"data row7 col6\" >-0.747881</td>\n",
       "      <td id=\"T_43fc7_row7_col7\" class=\"data row7 col7\" >1.000000</td>\n",
       "      <td id=\"T_43fc7_row7_col8\" class=\"data row7 col8\" >-0.494588</td>\n",
       "      <td id=\"T_43fc7_row7_col9\" class=\"data row7 col9\" >-0.534432</td>\n",
       "      <td id=\"T_43fc7_row7_col10\" class=\"data row7 col10\" >-0.232471</td>\n",
       "      <td id=\"T_43fc7_row7_col11\" class=\"data row7 col11\" >0.291512</td>\n",
       "      <td id=\"T_43fc7_row7_col12\" class=\"data row7 col12\" >-0.496996</td>\n",
       "      <td id=\"T_43fc7_row7_col13\" class=\"data row7 col13\" >0.249929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43fc7_level0_row8\" class=\"row_heading level0 row8\" >RAD</th>\n",
       "      <td id=\"T_43fc7_row8_col0\" class=\"data row8 col0\" >0.625505</td>\n",
       "      <td id=\"T_43fc7_row8_col1\" class=\"data row8 col1\" >-0.311948</td>\n",
       "      <td id=\"T_43fc7_row8_col2\" class=\"data row8 col2\" >0.595129</td>\n",
       "      <td id=\"T_43fc7_row8_col3\" class=\"data row8 col3\" >-0.007368</td>\n",
       "      <td id=\"T_43fc7_row8_col4\" class=\"data row8 col4\" >0.611441</td>\n",
       "      <td id=\"T_43fc7_row8_col5\" class=\"data row8 col5\" >-0.209847</td>\n",
       "      <td id=\"T_43fc7_row8_col6\" class=\"data row8 col6\" >0.456022</td>\n",
       "      <td id=\"T_43fc7_row8_col7\" class=\"data row8 col7\" >-0.494588</td>\n",
       "      <td id=\"T_43fc7_row8_col8\" class=\"data row8 col8\" >1.000000</td>\n",
       "      <td id=\"T_43fc7_row8_col9\" class=\"data row8 col9\" >0.910228</td>\n",
       "      <td id=\"T_43fc7_row8_col10\" class=\"data row8 col10\" >0.464741</td>\n",
       "      <td id=\"T_43fc7_row8_col11\" class=\"data row8 col11\" >-0.444413</td>\n",
       "      <td id=\"T_43fc7_row8_col12\" class=\"data row8 col12\" >0.488676</td>\n",
       "      <td id=\"T_43fc7_row8_col13\" class=\"data row8 col13\" >-0.381626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43fc7_level0_row9\" class=\"row_heading level0 row9\" >TAX</th>\n",
       "      <td id=\"T_43fc7_row9_col0\" class=\"data row9 col0\" >0.582764</td>\n",
       "      <td id=\"T_43fc7_row9_col1\" class=\"data row9 col1\" >-0.314563</td>\n",
       "      <td id=\"T_43fc7_row9_col2\" class=\"data row9 col2\" >0.720760</td>\n",
       "      <td id=\"T_43fc7_row9_col3\" class=\"data row9 col3\" >-0.035587</td>\n",
       "      <td id=\"T_43fc7_row9_col4\" class=\"data row9 col4\" >0.668023</td>\n",
       "      <td id=\"T_43fc7_row9_col5\" class=\"data row9 col5\" >-0.292048</td>\n",
       "      <td id=\"T_43fc7_row9_col6\" class=\"data row9 col6\" >0.506456</td>\n",
       "      <td id=\"T_43fc7_row9_col7\" class=\"data row9 col7\" >-0.534432</td>\n",
       "      <td id=\"T_43fc7_row9_col8\" class=\"data row9 col8\" >0.910228</td>\n",
       "      <td id=\"T_43fc7_row9_col9\" class=\"data row9 col9\" >1.000000</td>\n",
       "      <td id=\"T_43fc7_row9_col10\" class=\"data row9 col10\" >0.460853</td>\n",
       "      <td id=\"T_43fc7_row9_col11\" class=\"data row9 col11\" >-0.441808</td>\n",
       "      <td id=\"T_43fc7_row9_col12\" class=\"data row9 col12\" >0.543993</td>\n",
       "      <td id=\"T_43fc7_row9_col13\" class=\"data row9 col13\" >-0.468536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43fc7_level0_row10\" class=\"row_heading level0 row10\" >PTRATIO</th>\n",
       "      <td id=\"T_43fc7_row10_col0\" class=\"data row10 col0\" >0.289946</td>\n",
       "      <td id=\"T_43fc7_row10_col1\" class=\"data row10 col1\" >-0.391679</td>\n",
       "      <td id=\"T_43fc7_row10_col2\" class=\"data row10 col2\" >0.383248</td>\n",
       "      <td id=\"T_43fc7_row10_col3\" class=\"data row10 col3\" >-0.121515</td>\n",
       "      <td id=\"T_43fc7_row10_col4\" class=\"data row10 col4\" >0.188933</td>\n",
       "      <td id=\"T_43fc7_row10_col5\" class=\"data row10 col5\" >-0.355501</td>\n",
       "      <td id=\"T_43fc7_row10_col6\" class=\"data row10 col6\" >0.261515</td>\n",
       "      <td id=\"T_43fc7_row10_col7\" class=\"data row10 col7\" >-0.232471</td>\n",
       "      <td id=\"T_43fc7_row10_col8\" class=\"data row10 col8\" >0.464741</td>\n",
       "      <td id=\"T_43fc7_row10_col9\" class=\"data row10 col9\" >0.460853</td>\n",
       "      <td id=\"T_43fc7_row10_col10\" class=\"data row10 col10\" >1.000000</td>\n",
       "      <td id=\"T_43fc7_row10_col11\" class=\"data row10 col11\" >-0.177383</td>\n",
       "      <td id=\"T_43fc7_row10_col12\" class=\"data row10 col12\" >0.374044</td>\n",
       "      <td id=\"T_43fc7_row10_col13\" class=\"data row10 col13\" >-0.507787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43fc7_level0_row11\" class=\"row_heading level0 row11\" >B</th>\n",
       "      <td id=\"T_43fc7_row11_col0\" class=\"data row11 col0\" >-0.385064</td>\n",
       "      <td id=\"T_43fc7_row11_col1\" class=\"data row11 col1\" >0.175520</td>\n",
       "      <td id=\"T_43fc7_row11_col2\" class=\"data row11 col2\" >-0.356977</td>\n",
       "      <td id=\"T_43fc7_row11_col3\" class=\"data row11 col3\" >0.048788</td>\n",
       "      <td id=\"T_43fc7_row11_col4\" class=\"data row11 col4\" >-0.380051</td>\n",
       "      <td id=\"T_43fc7_row11_col5\" class=\"data row11 col5\" >0.128069</td>\n",
       "      <td id=\"T_43fc7_row11_col6\" class=\"data row11 col6\" >-0.273534</td>\n",
       "      <td id=\"T_43fc7_row11_col7\" class=\"data row11 col7\" >0.291512</td>\n",
       "      <td id=\"T_43fc7_row11_col8\" class=\"data row11 col8\" >-0.444413</td>\n",
       "      <td id=\"T_43fc7_row11_col9\" class=\"data row11 col9\" >-0.441808</td>\n",
       "      <td id=\"T_43fc7_row11_col10\" class=\"data row11 col10\" >-0.177383</td>\n",
       "      <td id=\"T_43fc7_row11_col11\" class=\"data row11 col11\" >1.000000</td>\n",
       "      <td id=\"T_43fc7_row11_col12\" class=\"data row11 col12\" >-0.366087</td>\n",
       "      <td id=\"T_43fc7_row11_col13\" class=\"data row11 col13\" >0.333461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43fc7_level0_row12\" class=\"row_heading level0 row12\" >LSTAT</th>\n",
       "      <td id=\"T_43fc7_row12_col0\" class=\"data row12 col0\" >0.455621</td>\n",
       "      <td id=\"T_43fc7_row12_col1\" class=\"data row12 col1\" >-0.412995</td>\n",
       "      <td id=\"T_43fc7_row12_col2\" class=\"data row12 col2\" >0.603800</td>\n",
       "      <td id=\"T_43fc7_row12_col3\" class=\"data row12 col3\" >-0.053929</td>\n",
       "      <td id=\"T_43fc7_row12_col4\" class=\"data row12 col4\" >0.590879</td>\n",
       "      <td id=\"T_43fc7_row12_col5\" class=\"data row12 col5\" >-0.613808</td>\n",
       "      <td id=\"T_43fc7_row12_col6\" class=\"data row12 col6\" >0.602339</td>\n",
       "      <td id=\"T_43fc7_row12_col7\" class=\"data row12 col7\" >-0.496996</td>\n",
       "      <td id=\"T_43fc7_row12_col8\" class=\"data row12 col8\" >0.488676</td>\n",
       "      <td id=\"T_43fc7_row12_col9\" class=\"data row12 col9\" >0.543993</td>\n",
       "      <td id=\"T_43fc7_row12_col10\" class=\"data row12 col10\" >0.374044</td>\n",
       "      <td id=\"T_43fc7_row12_col11\" class=\"data row12 col11\" >-0.366087</td>\n",
       "      <td id=\"T_43fc7_row12_col12\" class=\"data row12 col12\" >1.000000</td>\n",
       "      <td id=\"T_43fc7_row12_col13\" class=\"data row12 col13\" >-0.737663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43fc7_level0_row13\" class=\"row_heading level0 row13\" >target</th>\n",
       "      <td id=\"T_43fc7_row13_col0\" class=\"data row13 col0\" >-0.388305</td>\n",
       "      <td id=\"T_43fc7_row13_col1\" class=\"data row13 col1\" >0.360445</td>\n",
       "      <td id=\"T_43fc7_row13_col2\" class=\"data row13 col2\" >-0.483725</td>\n",
       "      <td id=\"T_43fc7_row13_col3\" class=\"data row13 col3\" >0.175260</td>\n",
       "      <td id=\"T_43fc7_row13_col4\" class=\"data row13 col4\" >-0.427321</td>\n",
       "      <td id=\"T_43fc7_row13_col5\" class=\"data row13 col5\" >0.695360</td>\n",
       "      <td id=\"T_43fc7_row13_col6\" class=\"data row13 col6\" >-0.376955</td>\n",
       "      <td id=\"T_43fc7_row13_col7\" class=\"data row13 col7\" >0.249929</td>\n",
       "      <td id=\"T_43fc7_row13_col8\" class=\"data row13 col8\" >-0.381626</td>\n",
       "      <td id=\"T_43fc7_row13_col9\" class=\"data row13 col9\" >-0.468536</td>\n",
       "      <td id=\"T_43fc7_row13_col10\" class=\"data row13 col10\" >-0.507787</td>\n",
       "      <td id=\"T_43fc7_row13_col11\" class=\"data row13 col11\" >0.333461</td>\n",
       "      <td id=\"T_43fc7_row13_col12\" class=\"data row13 col12\" >-0.737663</td>\n",
       "      <td id=\"T_43fc7_row13_col13\" class=\"data row13 col13\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x235b810d240>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def colour_medium_values_red(val):\n",
    "    color = 'red' if abs(val) > 0.7 else 'lightgrey'\n",
    "    return 'background-color: %s' % color\n",
    "C.style.applymap(colour_medium_values_red)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the \"new\" colinear variable pairs will likely have a lesser effect on the result, but they were always there, having some effect, regardless of how we define colinearity. It is for this reason, the degrees of multicollinearity, that there is no specific \"test\" that can say definitively that there is multicollinearity, or whether it is causing a problem.\n",
    "\n",
    "Let's review the model we saw in the last module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "est = smf.ols(formula='target ~ CRIM + ZN + INDUS + CHAS + NOX + RM + AGE + DIS + RAD + TAX + PTRATIO + B + LSTAT', \n",
    "              data=boston).fit()  # Does the constant for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>target</td>      <th>  R-squared:         </th> <td>   0.741</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.734</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   108.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 03 Jan 2023</td> <th>  Prob (F-statistic):</th> <td>6.72e-135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:51:57</td>     <th>  Log-Likelihood:    </th> <td> -1498.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th> <td>   3026.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   492</td>      <th>  BIC:               </th> <td>   3085.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   36.4595</td> <td>    5.103</td> <td>    7.144</td> <td> 0.000</td> <td>   26.432</td> <td>   46.487</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CRIM</th>      <td>   -0.1080</td> <td>    0.033</td> <td>   -3.287</td> <td> 0.001</td> <td>   -0.173</td> <td>   -0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ZN</th>        <td>    0.0464</td> <td>    0.014</td> <td>    3.382</td> <td> 0.001</td> <td>    0.019</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>INDUS</th>     <td>    0.0206</td> <td>    0.061</td> <td>    0.334</td> <td> 0.738</td> <td>   -0.100</td> <td>    0.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CHAS</th>      <td>    2.6867</td> <td>    0.862</td> <td>    3.118</td> <td> 0.002</td> <td>    0.994</td> <td>    4.380</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NOX</th>       <td>  -17.7666</td> <td>    3.820</td> <td>   -4.651</td> <td> 0.000</td> <td>  -25.272</td> <td>  -10.262</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RM</th>        <td>    3.8099</td> <td>    0.418</td> <td>    9.116</td> <td> 0.000</td> <td>    2.989</td> <td>    4.631</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AGE</th>       <td>    0.0007</td> <td>    0.013</td> <td>    0.052</td> <td> 0.958</td> <td>   -0.025</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DIS</th>       <td>   -1.4756</td> <td>    0.199</td> <td>   -7.398</td> <td> 0.000</td> <td>   -1.867</td> <td>   -1.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RAD</th>       <td>    0.3060</td> <td>    0.066</td> <td>    4.613</td> <td> 0.000</td> <td>    0.176</td> <td>    0.436</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TAX</th>       <td>   -0.0123</td> <td>    0.004</td> <td>   -3.280</td> <td> 0.001</td> <td>   -0.020</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PTRATIO</th>   <td>   -0.9527</td> <td>    0.131</td> <td>   -7.283</td> <td> 0.000</td> <td>   -1.210</td> <td>   -0.696</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B</th>         <td>    0.0093</td> <td>    0.003</td> <td>    3.467</td> <td> 0.001</td> <td>    0.004</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LSTAT</th>     <td>   -0.5248</td> <td>    0.051</td> <td>  -10.347</td> <td> 0.000</td> <td>   -0.624</td> <td>   -0.425</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>178.041</td> <th>  Durbin-Watson:     </th> <td>   1.078</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 783.126</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.521</td>  <th>  Prob(JB):          </th> <td>8.84e-171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.281</td>  <th>  Cond. No.          </th> <td>1.51e+04</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.51e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 target   R-squared:                       0.741\n",
       "Model:                            OLS   Adj. R-squared:                  0.734\n",
       "Method:                 Least Squares   F-statistic:                     108.1\n",
       "Date:                Tue, 03 Jan 2023   Prob (F-statistic):          6.72e-135\n",
       "Time:                        16:51:57   Log-Likelihood:                -1498.8\n",
       "No. Observations:                 506   AIC:                             3026.\n",
       "Df Residuals:                     492   BIC:                             3085.\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     36.4595      5.103      7.144      0.000      26.432      46.487\n",
       "CRIM          -0.1080      0.033     -3.287      0.001      -0.173      -0.043\n",
       "ZN             0.0464      0.014      3.382      0.001       0.019       0.073\n",
       "INDUS          0.0206      0.061      0.334      0.738      -0.100       0.141\n",
       "CHAS           2.6867      0.862      3.118      0.002       0.994       4.380\n",
       "NOX          -17.7666      3.820     -4.651      0.000     -25.272     -10.262\n",
       "RM             3.8099      0.418      9.116      0.000       2.989       4.631\n",
       "AGE            0.0007      0.013      0.052      0.958      -0.025       0.027\n",
       "DIS           -1.4756      0.199     -7.398      0.000      -1.867      -1.084\n",
       "RAD            0.3060      0.066      4.613      0.000       0.176       0.436\n",
       "TAX           -0.0123      0.004     -3.280      0.001      -0.020      -0.005\n",
       "PTRATIO       -0.9527      0.131     -7.283      0.000      -1.210      -0.696\n",
       "B              0.0093      0.003      3.467      0.001       0.004       0.015\n",
       "LSTAT         -0.5248      0.051    -10.347      0.000      -0.624      -0.425\n",
       "==============================================================================\n",
       "Omnibus:                      178.041   Durbin-Watson:                   1.078\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              783.126\n",
       "Skew:                           1.521   Prob(JB):                    8.84e-171\n",
       "Kurtosis:                       8.281   Cond. No.                     1.51e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.51e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that a warning has been produced indicating there there may be strong multicollinearity (or other numerical problems, but we will investigate the multicollinearity). The \"condition\" number is very large:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15113.517599134999"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.condition_number   # In general, values above 20 indicate a problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to see if multicollinearity is causing a problem is to check if the overall predictive power ($R^2$) appears high, but the individual t-statistics for each variable are low, having very wide confidence intervals. This indicates multicollinearity is likely at work, as the individual variables do not have much predictive power, but the overall model is still working.\n",
    "\n",
    "As mentioned earlier, any non-perfect multicollinearity still gives a good OLS estimator. What is perhaps surprising, is that such a model is still the Best Linear Unbiased Estimator for that model. This idea of OLS producing the Best Linear Unbiased Estimator comes from the Gauss-Markov theorem and is commonly referred to as the OLS being **BLUE**. This shows that for the given inputs, the OLS estimator produces the best model it can. Note, however, there may be a better combination of features or some other data manipulation that produces a better result (such as taking the log values of the inputs)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercises\n",
    "\n",
    "1. Research the Gauss-Markov theorem for BLUE. What are the key assumptions behind this finding? You'll see the word \"homoscedastic\", which we will investigate further in later modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1\n",
    "# BLUE = best linear unbiased estimator\n",
    "#   for a given Y = x*beta + e\n",
    "#   - x has a full rank, and x^Tx is invertible\n",
    "#   - linearity as the parameters we are estimating are linear\n",
    "#   - data must be randomly sampled from the population\n",
    "#   - non-collinearity meaning the independent variables should not be perfectly correlated with eachother\n",
    "#   - independent variables arent connected to the error term\n",
    "#   - error of the variance is constant regardless of the values in our independent variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extended exercise\n",
    "Another way to check multicollinearity is to see how stable coefficients for your input variables are when you change the sample of data. On this front, write code that performs the following test:\n",
    "\n",
    "1. Take a sample and compute the estimator using OLS\n",
    "2. Extract all coefficients from the model (check the `statsmodels` documentation)\n",
    "3. Repeat steps 1 & 2 many times (on the order of 100 or so should be fine)\n",
    "4. Plot the distribution of coefficients for each variable on separate graphs\n",
    "\n",
    "If there is a wide range in the values, multicollinarity may be a problem.\n",
    "\n",
    "Other tests for multicollinearity include altering the model slightly and observing large changes in the coefficients, particularly is the sign of the coefficient changes, i.e. a variable had a positive coefficient, and adding/removing a different, unrelated variable makes it suddenly negative - indicative of a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept    36.371617\n",
      "CRIM         -0.028666\n",
      "ZN            0.032561\n",
      "INDUS        -0.096924\n",
      "CHAS          0.750348\n",
      "NOX         -20.988534\n",
      "RM            4.746670\n",
      "AGE          -0.000714\n",
      "DIS          -1.379658\n",
      "RAD           0.171416\n",
      "TAX          -0.011105\n",
      "PTRATIO      -1.421754\n",
      "B             0.014274\n",
      "LSTAT        -0.181193\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# solution was already here so I just added comments\n",
    "# Extended exercise (copied off solutions)\n",
    "def run_experiment(data, target_variable_name='target', sample_size=100):\n",
    "    \n",
    "    \"\"\"\n",
    "    Fits an OLS to the data, predicting the target from all other variables\n",
    "    \"\"\"\n",
    "\n",
    "    # sample data\n",
    "    sample = data.sample(sample_size)\n",
    "    column_names = [col for col in data.columns if col != target_variable_name]\n",
    "\n",
    "    # Create formula, predicting target from the sum of all others\n",
    "    formula = \"{} ~ {}\".format(target_variable_name, str.join(\" + \", column_names))\n",
    "\n",
    "    # file model\n",
    "    model = smf.ols(formula=formula, data=sample).fit()\n",
    "    \n",
    "    # return parameters\n",
    "    return model.params\n",
    "\n",
    "# example: \n",
    "print(run_experiment(boston))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  0          1          2          3          4          5   \\\n",
      "Intercept  30.954893  29.482438  63.669066  47.937148  67.411532  55.298316   \n",
      "CRIM       -0.423893  -0.116215  -0.140651  -0.112825  -0.108579  -0.131324   \n",
      "ZN          0.056272   0.035793   0.031952   0.039153   0.056150   0.027036   \n",
      "INDUS      -0.114741  -0.140088   0.075940   0.258160  -0.073999  -0.338520   \n",
      "CHAS        1.776149  -2.361702   1.727301   3.999287  -0.725574   4.393273   \n",
      "\n",
      "                  6          7          8          9   ...         90  \\\n",
      "Intercept  56.054093  36.350839  15.943197  11.052787  ...  36.087031   \n",
      "CRIM       -0.121410  -0.076621   0.144527   0.065873  ...  -0.042352   \n",
      "ZN          0.063205   0.001910   0.033304   0.036226  ...   0.036209   \n",
      "INDUS      -0.085492  -0.194690  -0.005662  -0.180609  ...  -0.096581   \n",
      "CHAS        5.249656   0.953616   8.765477   4.858239  ...   1.628504   \n",
      "\n",
      "                  91         92         93         94         95         96  \\\n",
      "Intercept  43.346224  16.095004  61.455237  49.993994  50.472227  11.074460   \n",
      "CRIM       -0.156501  -0.007188  -0.158715  -0.056281  -0.060648  -0.142484   \n",
      "ZN          0.049933   0.024346   0.010920  -0.008770  -0.004610   0.005185   \n",
      "INDUS      -0.002879   0.203502   0.066096   0.115108  -0.054104   0.129790   \n",
      "CHAS       -0.616311   1.438113   3.782876   1.380794   2.705159   4.882245   \n",
      "\n",
      "                  97         98         99  \n",
      "Intercept  57.851000  48.151587  51.476203  \n",
      "CRIM        0.014961  -0.175709  -0.142935  \n",
      "ZN          0.078409   0.108368  -0.018502  \n",
      "INDUS       0.045358   0.159122  -0.043249  \n",
      "CHAS        7.653074   2.138669  -1.729407  \n",
      "\n",
      "[5 rows x 100 columns]\n",
      "Number of columns is 14\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x1080 with 15 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run experiment many times and concatenate parameter outputs into one data frame\n",
    "results = pd.concat([run_experiment(boston) for i in range(100)], axis=1)\n",
    "print(results.head())\n",
    "\n",
    "# retrieve columns\n",
    "columns = results.index.values\n",
    "n_columns = len(columns)\n",
    "print(\"Number of columns is \" + str(n_columns))\n",
    "n_rows, n_cols = 5, 3\n",
    "\n",
    "# Output histogram plot for each varaible\n",
    "fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(n_cols * 5, n_rows * 3))\n",
    "\n",
    "# we can plot all values of each variable for all 100 simulations (row-wise)\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        plot_number = (row * n_cols) + col\n",
    "        if plot_number >= n_columns:\n",
    "            break \n",
    "        column_name = columns[plot_number]\n",
    "        ax = axes[row, col]\n",
    "        ax.set_title(column_name)\n",
    "        \n",
    "        ax.hist(results.loc[column_name], bins=30)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we can see that some variables have a narrow range, while a few (INDUS, RAD, DIS) have a wide range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For solutions, see `solutions/histograms.py`*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Important points\n",
    "\n",
    "\n",
    "In the above tests, we mentioned that condition numbers above 20 are problematic. Like most things with multicollinarity, this is not a strict rule. Some people use 15, some use 30, and there is no distribution we can use to convert these to more meaningful likelihoods (as opposed to say, t-statistics).\n",
    "\n",
    "The degree of correlation that is significant is hard to decide on. Generally, the smaller the sample, the lower the cutoff point needs to be.\n",
    "\n",
    "That said, simply checking for correlation between two variables itself may not be sufficient to detect multicollinarity. An input variable might be a linear combination of other variables, and for this reason it might not be correlated highly with any single one of those variables. A way to think of this is whether a linear regression of some input variables would predict the other input variables.\n",
    "\n",
    "If you have some *a priori* knowledge of a relationship, you can try replacing your input variables with that linear combination. For instance, if you know that $X_2$ should have ten times the effect of $X_1$ in your model, you can remove them from your model, create a new variable $X_3= 10X_1 + X_2$ and use that instead.\n",
    "\n",
    "Do not just drop a variable because it causes multicollinearity. If you added it simply to experiment, then perhaps dropping it again is fine. However, if you had good reason to think that the variable belongs in your model, then don't just drop it to see if that fixes the issue. While this may address the multicollinarity, it can lead to specification error - which is when the model cannot accurately describe your output. This then has the follow on effect that your model might find unimportant-but-chance patterns between unrelated input variables and your output. This is known as overfitting. Your model is learning the random noise in your data, not the underlying trends. Simply dropping a variable may instead cause the opposite problem of underfitting, where there simply isn't enough data to properly model your output (think of using just the mean to predict the outcome, ignoring any input data)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "e4dc6b0224d27235dec988ead42f740f3c8067d08028a6940d609f8d318d6bb4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
