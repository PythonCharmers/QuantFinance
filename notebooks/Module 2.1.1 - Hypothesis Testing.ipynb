{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Quantitative Finance\n",
    "\n",
    "Copyright (c) 2019 Python Charmers Pty Ltd, Australia, <https://pythoncharmers.com>. All rights reserved.\n",
    "\n",
    "<img src=\"img/python_charmers_logo.png\" width=\"300\" alt=\"Python Charmers Logo\">\n",
    "\n",
    "Published under the Creative Commons Attribution-NonCommercial 4.0 International (CC BY-NC 4.0) license. See `LICENSE.md` for details.\n",
    "\n",
    "Sponsored by Tibra Global Services, <https://tibra.com>\n",
    "\n",
    "<img src=\"img/tibra_logo.png\" width=\"300\" alt=\"Tibra Logo\">\n",
    "\n",
    "\n",
    "## Module 2.1: Hypothesis Testing\n",
    "\n",
    "### 2.1.1 Hypothesis Testing\n",
    "\n",
    "Hypothesis testing is a formal method of testing your assumptions with data and statistics. With hypothesis testing, we create two (or more) competing hypothesis and decide which is more likely. In a variety of circumstances, we consider something \"unlikely\" if it has less than 5% chance of happening, but note this would mean that this happens in 1 in 20 experiments *anyway, just due to chance*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://imgs.xkcd.com/comics/significant.png\" title=\"'So, uh, we did the green study again and got no link. It was probably a--' 'RESEARCH CONFLICTED ON GREEN JELLY BEAN/ACNE LINK; MORE STUDY RECOMMENDED!'\" alt=\"Significant\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Above comic from https://xkcd.com/882/ Hint: count how many \"per-colour\" experiments were performed.)\n",
    "\n",
    "A common hypothesis pair is the following:\n",
    "\n",
    "* $H_0$, the Null hypothesis, is that any difference between the data in our sample, and the general population, is caused strictly by chance.\n",
    "* $H_A$, the Alternative hypothesis, is that there is a significant difference.\n",
    "\n",
    "The hypotheses must be mutually exclusive, as in it cannot be that both are true. They do not have to be exhaustive, i.e. account for all possible scenarios, but it is often the case. It is usually easier to compute the probability for $H_0$, i.e. $P(H_0)$ and then just compute $P(H_A) = 1 - P(H_0)$. This only applies if the pair is exhaustive.\n",
    "\n",
    "For example, we might have a sample, say trading firms using statistical analysis for decision making. Our Null hypothesis is that these firms are no different to the *population*, which may be either \"all trading firms\" or \"random people picking stocks\". We set up an experiment (more below) and find that we have a 4% chance that our Null hypothesis would generate results this extreme.\n",
    "\n",
    "We might then say that, because the chance is so low, we reject the Null hypothesis that any different is strictly by chance. \n",
    "\n",
    "Note that in this example, there is still a one in 25 chance of obtaining the result purely through \"luck\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importantly, this does *not* mean that we accept that using statistical analysis causing trading firms to profit more than normal. There may be some other factors involved that are causing the difference. While this might sound like [weasel words](https://en.wikipedia.org/wiki/Weasel_word), this type of inference happens all the time. For instance, firms using statistical analysis might get their advantage from simply a more careful and thorough analysis, rather than the specific statistical analysis they apply. They might be run by larger firms (who can afford the extra staff to do the statistical analysis and have access to more data), or many other factors.\n",
    "\n",
    "It could also be simply by chance, as the above comic demonstrates.\n",
    "\n",
    "This is a common logical fallacy called *Denying the antecedent*:\n",
    "    \n",
    "    If P, then Q.\n",
    "    Therefore, if not P, then not Q.\n",
    "\n",
    "Note that the conclusion above is **invalid** based solely on the condition. Our statistical tests generally tell us \"not P\", and we are left with a bit more evidence of \"not Q\", but never proof.\n",
    "\n",
    "Be wary of this fallacy. Statistics is often pessimistic in this regard - it rarely tells you that you are correct, it generally just tells you if there is a strong chance you are wrong.\n",
    "\n",
    "\n",
    "Another common pitfall, demonstrated by the above comic, is that when we run multiple tests at the same time, our notion of a probability threshold must change, otherwise it becomes **likely** that we observe a purely-by-chance outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run setup.ipy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Suppose we had $n$ independent tests. In each test, there is a 5% likelihood that the effect we are measuring is \"high\", for however that is defined. If we run all $n$ tests, what is the likelihood that *at least one test* measures a positive, high, outcome, for given $n$ values:\n",
    "\n",
    "- Two experiments\n",
    "- Ten experiments\n",
    "- Twenty experiments\n",
    "\n",
    "The above results can be computed with a calculator (or by hand if you are fine with leaving a fraction).\n",
    "\n",
    "#### Extended exercise\n",
    "\n",
    "Write a program with a function that does the following:\n",
    "\n",
    "- Compute 1000 random numbers from a normal distribution $N(0, 1)$\n",
    "- Compute the mean of those values\n",
    "\n",
    "Note the expected mean is 0.\n",
    "\n",
    "Plot a histogram of the means from running this function 10,000 times. How many of the results have a mean of more than 0.166?\n",
    "\n",
    "From your results here, note that even with *purely random data*, we can get very high differences between a same (running our function once) and the general population ($N(0, 1)$), just by chance in our we got our sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers:\n",
    "\n",
    "Pr(at least one test is \"high\") = 1- Pr(no test is \"high\")\n",
    "\n",
    "Given that tests are independent:\n",
    "Pr(no test is \"high\") = Pr(test 1 is not high) * Pr(test 2 is not high) * ... * Pr(test $n$ is not high)\n",
    "\n",
    "Therefore:\n",
    "\n",
    "Two experiments:\n",
    "Pr(at least one high test) = 1 - Pr(test 1 is not high) * Pr(test 2 is not high) = 1 - 0.95 * 0.95 = 0.0975 or 9.75%\n",
    "\n",
    "Ten experiment:\n",
    "Pr(at least one high test) = 1 - Pr(test 1 is not high) * Pr(test 2 is not high) * ... * Pr(test 10 is not high) = 1 - 0.95 ^ 10 = 0.401263 or 40.13%\n",
    "\n",
    "Twenty experiment:\n",
    "Pr(at least one high test) = 1 - Pr(test 1 is not high) * Pr(test 2 is not high) * ... * Pr(test 20 is not high) = 1 - 0.95 ^ 20 = 0.641514 or 64.15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computes 1000 random numbers from a normal distribution and averages them all\n",
    "def smean():\n",
    "    s = np.random.normal(0,1,1000)\n",
    "    return s.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017075782661522303"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one case of the average of 1000 means\n",
    "smean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generates a list of 10000 means of means\n",
    "iterations = 10000\n",
    "result = []\n",
    "for i in range(iterations):\n",
    "    result.append(smean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  20.,  154.,  562., 1520., 2494., 2594., 1678.,  726.,  218.,\n",
       "          34.]),\n",
       " array([-0.1101351 , -0.08851729, -0.06689947, -0.04528165, -0.02366384,\n",
       "        -0.00204602,  0.0195718 ,  0.04118961,  0.06280743,  0.08442525,\n",
       "         0.10604306]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plots a histsogram\n",
    "plt.hist(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#counts the number of times a value from the list is greater that 0.166\n",
    "counter = 0;\n",
    "for i in result:\n",
    "    if(i>0.166):\n",
    "        counter = counter + 1\n",
    "counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running this many times and only generating zeroes for the number of values greater than 0.166, I've included the reason as to why this is the case:\n",
    "\n",
    "using the equally weighted estimator Y = (1/1000) * x1 + (1/1000) * x2 + ... + (1/1000) * x1000 = (1/1000) * (x1 + x2 + ... + x1000)\n",
    "\n",
    "Since E[x1] = x_mu1, E[x2] = x_mu2 e.t.c.\n",
    "The expected value of the average of 1000 normal distributions is:\n",
    "E[Y] = (1/1000) * x_mu1 + (1/1000) * x_mu2 + ... + (1/1000) * x_mu1000\n",
    "\n",
    "Since all mu1 to mu1000 are expected to be 0:\n",
    "E[Y] = 0\n",
    "\n",
    "The variance of the average of 1000 normal distributions is:\n",
    "\n",
    "Var(Y) = Var((1/1000) * (x1 + x2 + ... + x1000))\n",
    "\n",
    "Var(Y) = (1/1000)^2 * Var(x1 + x2 + ... + x1000)\n",
    "\n",
    "Given that our distributions are iid\n",
    "\n",
    "Var(Y) = (1/1000)^2 * (Var(x1) + Var(x2) + ... + Var(x1000))\n",
    "\n",
    "Var(Y) = 1/1000\n",
    "\n",
    "Because all Var(xn) = 1, and there are 1000 values, 1000 * (1/1000000) = 1/1000\n",
    "\n",
    "Thus, we are actually calculating how many times in 10000 does the distribution N(0,0.001) exceed 0.166\n",
    "\n",
    "For simply one case:\n",
    "Pr(Y > 0.166) = Pr((Y-0)/sqrt(0.001) > 0.166/sqrt(0.001)) Normalizes Y to become a standard normal distribution N(0,1)\n",
    "\n",
    "Pr(Z > 0.166/sqrt(0.001)) = Pr(Z > 5.249381) which is approximately 0.000000414193026\n",
    "\n",
    "Using the same working as before:\n",
    "\n",
    "Pr(at least one test is > 0.166) = 1 - Pr(no test is >0.166) = 1 - (1-Pr(Y>0.166))^10000 = 0.004133 or 0.4133%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For solutions, see `solutions/hypothesis_one.py`*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note on answer from solution:\n",
    "\n",
    "To note, the answers use the mean of 100 standard normals meaning the variance would be 1/100 and standard deviation 1/10, therefore the Pr(Y>0.166) = Pr(Z>1.66) = 0.100586 which gives more measurable results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of hypotheses\n",
    "\n",
    "Any test of a hypothesis starts with a formal declaration of the hypothesis and its assumptions. Some general assumptions are things like \"tests are independent of each other\", \"sample drawn at random from the population\" and other factors that might reduce any latent causes that aren't being tested.\n",
    "\n",
    "The Null hypothesis is a \"business as normal\" hypothesis. The new medicine doesn't work. The new strategy didn't make a difference to sales. The sample doesn't differ from the population.\n",
    "\n",
    "The Alternative hypothesis is that our intervention caused some change. For instance, the new medicine reduces illness. Sales increased significantly from the new strategy. The sample is different from the population.\n",
    "\n",
    "Normally we are interested in computing some statistic and then identifying what the likelihood is of that statistic having occurred by chance, based on our assumptions.\n",
    "\n",
    "A commonly used method here is a p-test, where we are testing if a mean is different (>, <, $\\neq$) to the population mean, when we assume the mean from a sample is otherwise drawn from a normal distribution. For instance, if we roll 100 dice, we get an expected value of 350, and a normal distribution of results centred around this value:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336\n"
     ]
    }
   ],
   "source": [
    "dice_rolls = np.random.randint(1, 7, size=100)\n",
    "print(dice_rolls.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = np.array([np.random.randint(1, 7, size=100).sum() for i in range(10000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(sums, bins=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we suspected a dice to be \"loaded\", that is, it is more likely to come up with a given number, we might run an experiment. We might suspect this dice to roll higher numbers more frequently than lower numbers. Our hypothesis is:\n",
    "\n",
    "$H_0$: The dice has a true expected value of 3.5\n",
    "\n",
    "$H_A$: The dice has an expected value of significantly more than 3.5\n",
    "\n",
    "\n",
    "We roll this suspect dice 100 times, and compute the mean. We get a total value of 410. We then do this experiment 3 more times, getting values of 420, 400, 405. This is unlikely, as it is an expected value of around 4.1. This would fit with our hypothesis, but how unlikely is it? We will look into this further in a later module, but for now, we can look up this value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t stat: 13.7602, p value: 0.000831\n"
     ]
    }
   ],
   "source": [
    "t_stat, p_val = stats.ttest_1samp([410, 420, 400, 405], 350)\n",
    "print('t stat: {:.4f}, p value: {:4f}'.format(t_stat, p_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The t-stat, while important, isn't really of value here. It is an intermediate statistic we then use to compute the p-value, which is what is normally needed here. The p-value is simply a probability, which you can get in any valid method you can think of. In this case, it is a statistical test \"what is the probability of getting a t stat of this size by chance?\".\n",
    "\n",
    "#### Exercise\n",
    "\n",
    "1. If we assume a confidence level of 0.05 qualifies as \"significant\", what can we say about our hypothesis?\n",
    "2. As a percentage, what is the likelihood of the given samples being obtained by chance?\n",
    "3. Can we suggest that the dice rolls values of 6 more frequently than other values?\n",
    "4. Review the documentation for all of the `scipy.stats.ttest_???` functions and identify when each would be needed.\n",
    "\n",
    "\n",
    "Note there are also T tests in the `statsmodels` package, which can be called in a similar way.\n",
    "\n",
    "\n",
    "#### Extended Exercise\n",
    "\n",
    "Create an alternative hypothesis and experiment to address question 3 above. How can we test if a dice rolls 6s more frequently?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers:\n",
    "\n",
    "##### Exercises\n",
    "We reject the null hypothesis at the 5% level since our p value is less than 0.05\n",
    "\n",
    "If the null hypothesis were true and the die is not loaded, then we would see this result in 0.0831% of cases\n",
    "\n",
    "We cannot say with certainty that the die is weighted in such a way to roll more sixes and thus less ones (given opposite sides of a die summing to 7, and assuming that apart from being weighted that this is a standard die) however this would be the most likely case. With averages from 4 to 4.2, the die functions very similar to a balanced die that cannot roll a 1. However, without observing the actual rolls we cannot say that 6 appears more frequently as the die could be weighted to roll more fives.\n",
    "\n",
    "scipy.stats.ttest_ind is used for determining whether two independent samples have the same mean:\n",
    "\n",
    "Should be used for two arraytype datasets\n",
    "\n",
    "scipy.stats.ttest_1samp is used to calculate the T score for a sample against a given mean:\n",
    "\n",
    "Used as above, when we have an arraytype dataset that we want to test against an expected average.\n",
    "\n",
    "scipy.stats.ttest_ind_from_stats is a T test for two datasets where the null is that they have the \"identical average values\":\n",
    "\n",
    "Used if we have the means variances and sizes of two datasets and we want to deteremine through statistical testing whether they have signifcant difference in their means.\n",
    "\n",
    "scipy.stats.ttest_rel same as scipy.stats.ttest_ind but for related or repeated sample:\n",
    "\n",
    "Used if the two array datasets are related or were sampled from the same population.\n",
    "\n",
    "##### Extended Exercise\n",
    "\n",
    "H0: Pr(rolling a 6) = 1/6\n",
    "HA: Pr(rolling a 6) > 1/6\n",
    "\n",
    "These are our null and alternate hypotheses, at this point the die would be roll some number of times, above uses 100 die results however rolling 1000 times would not be too difficult (though it would be time consuming). If the die is weighted/unfair then the greater number of rolls will improve the accuracy of our result.\n",
    "We can then generate a binary counter for whether a six is observed (as well as the other numbers generated as it would be just as interesting to see if the other numbers have equal chances of being rolled or if they were also imbalanced between themselves). Thus our data would be an array of 0s indicating rolls of 1, 2, 3, 4 or 5 and 1s indicating 6s. \n",
    "\n",
    "We can then use scipy.stats.ttest_1samp (we can include in the functions parameters that the test is one sided as we are testing to see of the 1000 identifier values are greater than 1/6.) This will produce the T score and thus the statistical likelihood that 6s are appearing the expected number of times or greater than average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For solutions, see `solutions/inferring_statistics.py`*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common problems and issues\n",
    "\n",
    "### Large P values\n",
    "\n",
    "If you do not get a lower p-value, you do not have a strong result. We cannot accept the null hypothesis, we just \"fail to reject\" it.\n",
    "\n",
    "If we were to run our above statistic and get a p value of 0.2 (assuming a threshold of significance of 0.05), we do not \"accept the null hypothesis\", we simply fail to reject it at our significance level.\n",
    "\n",
    "\n",
    "### Thresholds\n",
    "\n",
    "It is important also to ensure the p value threshold is set *before* the experiment, and not after you get your results. If you do not, it is tempting to just \"change\" the threshold after you get your results. This removes any independence you had in your result, and the experimenter is effectively arbitrarily changing the result - why bother doing the test in this case?\n",
    "\n",
    "A common value for the threshold is 0.05. There is no basis in this value, it is just \"what is generally used\". If your hypothesis is a matter of life or death, this value is probably too high. If it is of no great consequence, it might be too low. Reason about the value before blindly accepting on.\n",
    "\n",
    "Also note that people are generally terrible dealing with low probabilities. The difference between a false positive of 0.02 and one of 0.01 is \"one in fifty\" compared to \"one in one hundred\". That's twice as likely for the first. Typically, it can be better to estimate with an intuitive \"one in ...\" amount, then convert that to a percentage.\n",
    "\n",
    "\n",
    "### Multiple Simultaneous experiments\n",
    "\n",
    "With modern computers able to run simulations continuously, and at scale, a common issue arising is that the p-value thresholds most commonly used (i.e. 0.05) are only valid for individual tests.\n",
    "\n",
    "For example, suppose we had the following hypothesis:\n",
    "\n",
    "$H_0$: Stock price changes are random for IBM on Mondays\n",
    "\n",
    "$H_A$: Stock prices are more likely to drop on Mondays.\n",
    "\n",
    "\n",
    "We might test this hypothesis and get a p value of 0.2, indicating there is insufficient evidence to reject the null hypothesis, and therefore do not automatically buy on Tuesdays after the drop.\n",
    "\n",
    "We might then consider \"does this pattern hold on any other day?\". So we consider the same hypothesis, but for Tuesday, Wednesday, Thursday and Friday. We find the following significance levels:\n",
    "\n",
    "* Monday: 0.2\n",
    "* Tuesday: 0.1\n",
    "* Wednesday: 0.8\n",
    "* Thursday: 0.04\n",
    "* Friday: 0.5\n",
    "\n",
    "Aha! Thursdays have a *highly significant* effect. We fail to reject all other null hypothesis, accept the Thursday one, and start trading. \n",
    "\n",
    "What went wrong?\n",
    "\n",
    "\n",
    "#### Exercise\n",
    "\n",
    "1. Research the \"Multiple comparisons problem\" and identify a way to fix our hypothesis. We still want to check if any day has a significant value for our hypothesis, but we want to do it in a rigorous way.\n",
    "2. Does our finding hold after adjusting? The solution uses one specific method of fixing the thresholds - if you choose another, then you may get another answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers:\n",
    "\n",
    "The errors made here are similar to the jellybean case at the start of this Module however the one of the biggest issues here is we should not immediately start trading. It very well may be the case that the IBM stock price falls on a Thursday, however we should try to find some cause of this relation. We can test this hypothesis however without any backing of why the stock prices drop on Thursday, this information probably would not help us at all.\n",
    "\n",
    "Multiple comparisons problem occurs when one makes too make simultaneous statistical inferences (here being the five alternate hypotheses of \"stock prices are more likely to drop on xxxxxday.) The more simultaneous inferences, the greater the probability that one of them will randomly be significant.\n",
    "\n",
    "The best way to correct for the multiple comparisons problem is to use Bonferroni correction AKA multiple comparisons correction. This is simply taking our desired level of significance and distributing it to all the cases. Here since we are unsure which of the days would produce a result statistically relevant we should divide our p threshold by 5, giving us a 0.01 critical value. Thus, we observe that all five days are not statistically significant at the 0.01 and the alternate hypothesis should be rejected.\n",
    "\n",
    "We may also use the Sidak correction method, the formula for which is alpha_new = 1- (1- alpha_old)^(1/no. of test) which gives a new critical value of 0.0102. Using this correction method, we still reject all alternate hypotheses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For solutions, see `solutions/multiple_comparisons.py`*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulations\n",
    "\n",
    "A topic we will get into in more detail later, but a useful one to touch on here, is the use of simulations for computing p values. When testing a hypothesis, you can use a simulation of your null hypothesis, and then with that simulation, estimate the likelihood of findings like your sample. For instance:\n",
    "\n",
    "$H_0$: The AUD/USD change is a random walk (that is, there is no pattern)\n",
    "\n",
    "$H_A$: The AUD/USD change tends to follow the previous change with lag 1 (that is, if the previous change was up, it is more likely this change will be up too)\n",
    "\n",
    "\n",
    "A little more formally, if we ignore \"no change\", we might say that $p$, the proportion of changes that are consistent with the previous change, is 50%, when we have:\n",
    "\n",
    "$H_0: p = 0.5$\n",
    "\n",
    "$H_A: p > 0.5$\n",
    "\n",
    "\n",
    "To do this, we might analyse some data and find that we get a proportion with a value of 0.6, that is, the proportion of times that a change follows the previous change is 0.6 (60%). Is this \"significant\"?\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">That value above is artificial - we compute the real data in the exercise later</div>\n",
    "\n",
    "To test this, we can create a simulation. In this simulation, we are focused on our null hypothesis - that there is no relationship between a change and the previous one. We might run our experiment for one year's worth of data (i.e. 365 changes), with each change randomly and uniformly chosen from \"up\" or \"down\". We then measure the proportion values to get our result from the simulation. Repeat many times, and you can then use this to estimate the p-value, or the probability that the null hypothesis is true.\n",
    "\n",
    "\n",
    "#### Exercises\n",
    "\n",
    "1. Download the USD/AUD prices from Quandl\n",
    "2. Identify whether each change is \"up\" or \"down\" and compute the sample proportion value (it was 0.6 in the artificial data above)\n",
    "\n",
    "#### Extended Exercise\n",
    "\n",
    "1. Create and run the simulation mentioned above, where we simulate a random walk scenario and compute the proportion of times a change corresponds with the previous change.\n",
    "2. Run the simulation many times\n",
    "3. Compute the p value and determine whether to accept or reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For solutions, see `solutions/hypothesis_two.py`*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests for specific attributes\n",
    "\n",
    "Often it is of use to know that data has a certain property, for instance it is normally distributed, correlated, or whether two samples are basically the same or not.\n",
    "\n",
    "\n",
    "### Correlation between variables\n",
    "\n",
    "These tests are designed to test whether two samples of data are independent of each other, or if a dependency exists:\n",
    "\n",
    "$H_0$ the two samples tested are independent from each other\n",
    "\n",
    "$H_A$ the two samples tested have a dependency between them\n",
    "\n",
    "* Spearman's Rank Correlation, implemented as `scipy.stats.spearmanr`\n",
    "* Pearson's correlation coefficient, implemented as `scipy.stats.pearsonr`\n",
    "* Chi-Squared test, implemented as `scipy.stats.chi2_contingency` and `statsmodels.stats.proportion.proportions_chisquare`\n",
    "\n",
    "\n",
    "### Gaussian Distribution Tests\n",
    "\n",
    "There are a few tests designed to test that a distribution is Gaussian (normal). They include:\n",
    "\n",
    "* The Shapiro-Wilk test, implemented as `scipy.stats.shapiro`\n",
    "* D’Agostino’s $K^2$, implemented as `scipy.stats.normaltest`\n",
    "* Kolmogorov-Smirnov, implemented as `scipy.stats.kstest` and `statsmodels.stats.diagnostic.kstest_normal`\n",
    "* Anderson-Darling, implemented as `scipy.stats.anderson`\n",
    "\n",
    "Each of the above tests against the hypothesis:\n",
    "\n",
    "$H_0$ the data has a Gaussian distribution\n",
    "\n",
    "$H_A$ the data does not have a Gaussian distribution\n",
    "\n",
    "\n",
    "### Are two samples equal?\n",
    "\n",
    "These tests assert that, given two samples, they are effectively equal (i.e. they came from the same distribution):\n",
    "\n",
    "* Student's t-test, as identified earlier, implemented in quite a few methods in both scipy and statsmodels\n",
    "* Analysis of Variance Test (ANOVA), `scipy.stats.f_oneway` and `statsmodels.api.stats.anova_lm` (among a few other ways to call it).\n",
    "* Mann-Whitney U Test, implemented as `scipy.stats.manwhitneyu`\n",
    "* Wilcoxon Signed Rank Test, implemented as `scipy.stats.wilcoxon`\n",
    "\n",
    "\n",
    "Note that while the tests in these categories have the same purpose, they are not the same in terms of quality, speed, and even coding signatures! Always check the documentation for the function you are using first, before using it in practice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extended Exercise\n",
    "\n",
    "Using a simulation, create your own function that can compute the t-test and p values for a Student's t-test.\n",
    "\n",
    "For a comparison of two independent samples (i.e. \"here are two samples, do they come from the same distribution?\"), the t value is computed as:\n",
    "\n",
    "$ t(X_1, X_2) = \\frac{\\bar{X_1} - \\bar{X_2}}{s}$\n",
    "\n",
    "\n",
    "Where:\n",
    "\n",
    "* $\\bar{X_1}$ is the mean of sample $X_1$\n",
    "* s is the standard error of the difference, which is:\n",
    "\n",
    "$e_1 = \\frac{\\sigma_1}{\\sqrt(n_1)}$\n",
    "\n",
    "Where $\\sigma_1$ is the standard deviation of $X_1$ and $n_1$ is the number of observations in $X_1$, This is the \"standard error\" of $X_1$.\n",
    "\n",
    "Then,\n",
    "\n",
    "$s = \\sqrt{e_1^2 + e_2^2}$\n",
    "\n",
    "Which is the standard error of the difference between the means.\n",
    "\n",
    "The output of your code should be a pandas DataFrame where the index values are the p-values we are testing (i.e. 0.01, 0.05, 0.1, 0.2) and the columns are the degrees-of-freedom, which is how many data points in both $X_1$ and $X_2$, subtracting 2. Values to compute are 5, 10, 20, 50, 100 (and so on if you are inclined).\n",
    "\n",
    "The values can be computed via simulation - that is, draw many random samples, and compute the likelihood of getting a t value at least that high between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def student(set1,set2):\n",
    "    # Numerator\n",
    "    num = np.mean(set1)-np.mean(set2)\n",
    "    \n",
    "    # Errors\n",
    "    err1 = np.std(set1)/np.sqrt(len(set1))\n",
    "    err2 = np.std(set2)/np.sqrt(len(set2))\n",
    "    # Denominator\n",
    "    den = np.sqrt(err1*err1 + err2*err2)\n",
    "    \n",
    "    # Result\n",
    "    result = num/den\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim(size):\n",
    "    size1 = np.random.randint(2,size)\n",
    "    size2 = size + 2 - size1\n",
    "    \n",
    "    _set1 = np.random.randn(size1)\n",
    "    _set2 = np.random.randn(size2)\n",
    "    \n",
    "    return student(_set1, _set2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.01: {5: -4.347020181122642,\n",
       "  10: -3.7534309545942137,\n",
       "  20: -3.5200182854273523,\n",
       "  50: -3.0243717659727767,\n",
       "  100: -2.702060412618033},\n",
       " 0.025: {5: -3.3298051168147835,\n",
       "  10: -2.8786338725864695,\n",
       "  20: -2.63852437222008,\n",
       "  50: -2.400234898219118,\n",
       "  100: -2.2272163133976433},\n",
       " 0.05: {5: -2.620179796328343,\n",
       "  10: -2.2960005832119927,\n",
       "  20: -2.0850939244538655,\n",
       "  50: -1.8852402698377235,\n",
       "  100: -1.7568449695517905},\n",
       " 0.1: {5: -1.8701224898632154,\n",
       "  10: -1.7021257051140424,\n",
       "  20: -1.5594022663945055,\n",
       "  50: -1.4087288445729815,\n",
       "  100: -1.3748027359994346},\n",
       " 0.25: {5: -0.9398256728031857,\n",
       "  10: -0.8445400393685317,\n",
       "  20: -0.7769662691429423,\n",
       "  50: -0.6896809753435514,\n",
       "  100: -0.6958804168769764},\n",
       " 0.4: {5: -0.34111838108722703,\n",
       "  10: -0.33537928225777236,\n",
       "  20: -0.30208453840077504,\n",
       "  50: -0.23066449107249015,\n",
       "  100: -0.26143571458222453}}"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numsims = 10000\n",
    "data = {0.01:{}, 0.025:{}, 0.05:{}, 0.1:{}, 0.25:{}, 0.4:{}}\n",
    "for i in [5, 10, 20, 50, 100]:\n",
    "    results = []\n",
    "    for j in range(numsims):\n",
    "        results.append(sim(i))\n",
    "    results.sort()\n",
    "    # After ordering, the largest value in the smallest 1% of data is at position numsims * 0.01\n",
    "    # This is true for all other p values we are testing, 5%, 10% and 20% = numsims* their % thus:\n",
    "    for k in [0.01, 0.025, 0.05, 0.1, 0.25, 0.4]:\n",
    "        index = int(k*numsims)\n",
    "        data[k][i] = results[index]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.010</th>\n",
       "      <th>0.025</th>\n",
       "      <th>0.050</th>\n",
       "      <th>0.100</th>\n",
       "      <th>0.250</th>\n",
       "      <th>0.400</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-4.347020</td>\n",
       "      <td>-3.329805</td>\n",
       "      <td>-2.620180</td>\n",
       "      <td>-1.870122</td>\n",
       "      <td>-0.939826</td>\n",
       "      <td>-0.341118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-3.753431</td>\n",
       "      <td>-2.878634</td>\n",
       "      <td>-2.296001</td>\n",
       "      <td>-1.702126</td>\n",
       "      <td>-0.844540</td>\n",
       "      <td>-0.335379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-3.520018</td>\n",
       "      <td>-2.638524</td>\n",
       "      <td>-2.085094</td>\n",
       "      <td>-1.559402</td>\n",
       "      <td>-0.776966</td>\n",
       "      <td>-0.302085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>-3.024372</td>\n",
       "      <td>-2.400235</td>\n",
       "      <td>-1.885240</td>\n",
       "      <td>-1.408729</td>\n",
       "      <td>-0.689681</td>\n",
       "      <td>-0.230664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>-2.702060</td>\n",
       "      <td>-2.227216</td>\n",
       "      <td>-1.756845</td>\n",
       "      <td>-1.374803</td>\n",
       "      <td>-0.695880</td>\n",
       "      <td>-0.261436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0.010     0.025     0.050     0.100     0.250     0.400\n",
       "5   -4.347020 -3.329805 -2.620180 -1.870122 -0.939826 -0.341118\n",
       "10  -3.753431 -2.878634 -2.296001 -1.702126 -0.844540 -0.335379\n",
       "20  -3.520018 -2.638524 -2.085094 -1.559402 -0.776966 -0.302085\n",
       "50  -3.024372 -2.400235 -1.885240 -1.408729 -0.689681 -0.230664\n",
       "100 -2.702060 -2.227216 -1.756845 -1.374803 -0.695880 -0.261436"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = pd.DataFrame(data)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For solutions, see `solutions/simulation_ttest.py`*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
